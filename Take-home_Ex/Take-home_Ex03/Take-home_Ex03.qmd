---
title: "Take-home Exercise 3"
author: "Arya Siahaan"
date: "May 15, 2024"
date-modified: "June 9, 2024"
execute: 
  eval: true
  echo: true
  warning: false
  freeze: true
---

# VAST Challenge 2024

### Mini-Challenge 2:

#### Background

In Oceanus, the island's economy thrives on the movement of seafaring vessels, particularly those operated by commercial fishing companies, indicating a healthy economic state. However, a major event has disrupted these routines: SouthSeafood Express Corp was caught engaging in illegal fishing. This scandal caused significant turmoil within the close-knit fishing community. FishEye International, a non-profit dedicated to combating illegal fishing, seeks assistance to understand the impact of this event. They have been gathering and processing data on ship movements and shipping records to create CatchNet: the Oceanus Knowledge Graph. While analysts at FishEye ensure data accuracy, they require assistance to develop analytical capabilities for this data.

#### Tasks and Questions:

FishEye analysts require assistance in performing geographic and temporal analysis of the CatchNet data to prevent future instances of illegal fishing. The task involves developing innovative visual analytics tools and workflows designed to identify and understand signatures of various behaviors. One key objective is to visualize the signature of SouthSeafood Express Corp's illegal activities. Additionally, there is a need to create a workflow capable of detecting other instances of illegal behavior within the data. These efforts are crucial for enhancing FishEye's ability to monitor and combat illegal fishing effectively. This exercise will attempt to address Question 1 and Question 3 of this challenge.

##### Question 1

FishEye analysts have long wanted to better understand the flow of commercially caught fish through Oceanus’s many ports. But as they were loading data into CatchNet, they discovered they had purchased the wrong port records. They wanted to get the ship off-load records, but they instead got the port-exit records (essentially trucks/trains leaving the port area). Port exit records do not include which vessel that delivered the products. Given this limitation, develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?

##### Question 3

To support further Fisheye investigations, develop visual analytics workflows that allow you to discover other vessels engaging in behaviors similar to SouthSeafood Express Corp’s illegal activities? Provide visual evidence of the similarities.

## Getting Started

### Loading the required R library packages

The following code chunk utilises the [`p_load()`](https://www.rdocumentation.org/packages/pacman/versions/0.5.1/topics/p_load) function from the [pacman](https://github.com/trinker/pacman) package to ensure that the necessary packages are available in the R environment. If the packages are already installed on the computer, [`p_load()`](https://www.rdocumentation.org/packages/pacman/versions/0.5.1/topics/p_load) will load them. If they are not installed, it will first install them and then load them into the R environment.

```{r}
pacman::p_load(tidyverse, jsonlite, igraph, 
               tidygraph, ggraph, SmartEDA, skimr,
               lubridate, ggplot2, DataExplorer) 
```

### Loading The Data

The dataset is in the form of a json file and it is available for download at the [Vast Challenge 2024](https://vast-challenge.github.io/2024/index.html).

```{r}
mc2_data <- fromJSON("data/mc2.json")
```

This line loads the JSON dataset into R using the jsonlite package. The dataset is stored in the mc2_data variable.

## Data Preparation

### Wrangling and tidying edges

#### Extracting edges

```{r}
# Wrangling and tidying edges
mc2_edges <- as_tibble(mc2_data$links) %>% distinct()
# Converts the date columns to POSIXct datetime format using the as_datetime function from the lubridate package, then display it with  glimpse() to confirm if the process have been performed correctly.
mc2_edges <- mc2_edges %>%
  mutate(date = as_datetime(date), time = as_datetime(time))
glimpse(mc2_edges)
```

The code above converts the 'links' part of the dataset into a tibble and removes duplicates. It then converts date and time information into proper datetime formats using lubridate, and extracts just the date to a new column.

#### Splitting and Tidying the 'type' Column

```{r}
word_list <- strsplit(mc2_edges$type, "\\.")
max_elements <- max(lengths(word_list)) #to find the maximum number of elements in any split
word_list_padded <- lapply(word_list, 
function(x) c(x, rep(NA, max_elements - length(x)))) #to pad shorter splits with NA values to make them all the same length.
word_df <- do.call(rbind, word_list_padded)
colnames(word_df) <- paste0("event", 1:max_elements)

# Since the output above is a matrix, the code chunk below is used to convert word_df into a tibble data.frame.
word_df <- as_tibble(word_df) %>%
  select(event2, event3)


# The code chunk below appends the extracted columns back to mc2_edges tibble data.frame
mc2_edges <- mc2_edges %>%
  cbind(word_df)
```

This code splits the 'type' column into multiple components, pads shorter entries with NAs, and integrates them back into the mc2_edges dataframe as new columns.

After cleaning and preparing mc2_edges dataframe, I want to understand how the newly formed structure looks like, lets use the DataExplorer package to visualize it.

::: panel-tabset
## The plot

![](images/clipboard-2055116904.png)

![](images/clipboard-1180112888.png)

## The code

```{r}
#| eval: false
# Plot introduction of the data
plot_intro(mc2_edges, title = "Introduction of mc2_edges Data")
```
:::

::: panel-tabset
## The plot

![](images/clipboard-2619173514.png)

## The code

```{r}
#| eval: false
# Generate and display the data structure plot
plot_str(mc2_edges)

```
:::

::: panel-tabset
## The plot

![](images/clipboard-299140884.png)

## The code

```{r}
#| eval: false
# Plot missing values
plot_missing(mc2_edges, title = "Missing Values in mc2_edges Data")

```
:::

After the above EDA, I will remove columns that is unnecessary to answer the task at hand

#### Dropping Unnecessary Columns

```{r}
mc2_edges_cleaned <- mc2_edges %>%
  select(-c(`type`, `_last_edited_by`, `_date_added`, `_last_edited_date`, `_raw_source`, `_algorithm`, `key`,  `data_author`, `aphorism`, `holiday_greeting`, `wisdom`, `saying of the sea`))

glimpse(mc2_edges_cleaned)
```

Removes unnecessary columns from the dataset that are not needed for analysis, cleaning up the data. Glimpse() is then used to display the structure of the data.

### Wrangling and tidying nodes

#### Extracting Nodes and Removing Duplicates

```{r}

mc2_nodes <- as_tibble(mc2_data$nodes) %>%
  distinct()

glimpse(mc2_nodes)

```

This converts the nodes data to a tibble and removes duplicate rows, then displays the structure of the data using glimpse().

I plan to make use of the date column, but since it is in character format, I will convert it first into date format using lubridate package and glimpse it again to verify the changes.

```{r}

mc2_nodes <- mc2_nodes %>% 
  mutate(date = as_date(date)) 

glimpse(mc2_nodes)

```

There are two more additional data issues can be observed. They are:

The values in Activities and fish_species_present fields are in list data type, which will affect the ability to process and to analyse the data. As shown in the screenshot below, some values in the Activities field are not ready to be analyse without further tidying (i.e. removing c(““)).

Tidying text field In the code chunk below, mutate() of dplyr and gsub() of Base R are used to perform the data tidying task.

This cleans up the Activities and fish_species_present columns by removing unnecessary characters.

```{r}

mc2_nodes <- mc2_nodes %>%
  mutate(Activities = gsub("c[(]", "", Activities)) %>% 
  mutate(Activities = gsub("\"", "", Activities)) %>%
  mutate(Activities = gsub("[)]", "", Activities)) 

mc2_nodes <- mc2_nodes %>%
  mutate(fish_species_present = gsub("c[(]", "", fish_species_present)) %>% 
  mutate(fish_species_present = gsub("\"", "", fish_species_present)) %>%
  mutate(fish_species_present = gsub("[)]", "", fish_species_present)) 
```

Now, lets use DataExplorer package again to visualize it

::: panel-tabset
## The plot

![](images/clipboard-4088556349.png)

![](images/clipboard-290209426.png)

## The code

```{r}
#| eval: false
# Plot introduction of the data
plot_intro(mc2_nodes, title = "Introduction of mc2_nodes Data")
```
:::

::: panel-tabset
## The plot

![](images/clipboard-1740825281.png)

## The code

```{r}
#| eval: false
# Generate and display the data structure plot
plot_str(mc2_nodes)

```
:::

::: panel-tabset
## The plot

![](images/clipboard-1008176763.png)

## The code

```{r}
#| eval: false
# Plot missing values
plot_missing(mc2_nodes, title = "Missing Values in mc2_nodes Data")

```
:::

#### Dropping unnecessary Columns

```{r}
mc2_nodes_cleaned <- mc2_nodes %>%
  select(-c(`_last_edited_by`, `_date_added`, `_last_edited_date`, `_raw_source`, `_algorithm`, `style`))
glimpse(mc2_nodes_cleaned)
```

Removes additional unneeded columns from the nodes data frame.

```{r}

# Inspect the edges dataframe
glimpse(mc2_edges_cleaned)

# Inspect the nodes dataframe
glimpse(mc2_nodes_cleaned)
```

Let's investigate further on what is in the `type` column from mc2_nodes_cleaned dataframe.

```{r}
unique(mc2_nodes_cleaned$type)
```

```{r}
vessel_type_counts <- mc2_nodes_cleaned %>%
  group_by(type) %>%
  summarise(count = n())

# Display the result
print(vessel_type_counts)
```

This particular column contains variety of different data, some of them seems interesting and useful for analysis, they are:

-   Entity.Commodity.Fish

-   Entity.Document.DeliveryReport

-   Entity.Location.City

-   Entity.Location.Point

-   Entity.Location.Region

-   Entity.Vessel.CargoVessel

-   Entity.Vessel.FishingVessel

The others seems unnecessary.

I will try to make separate dataframe for each of them.

Here I can see the type of vessel and how many of each are recorded in the dataframe.

I'm only interested in the fishing vessel and the cargo vessel, and apparently there 178 fishing vessels and 100 cargo vessels, next so I will try to filter all the rows that only contain fishing vessels and cargo vessels

Filter all the rows containing fishing_vessel

```{r}
# Filter fishing vessels and rename specific columns while keeping all others
fishing_vessel <- mc2_nodes_cleaned %>%
  filter(type %in% c("Entity.Vessel.FishingVessel")) %>%
  rename(
    vessel_type = type,
    fishing_vessel_id = id,
    fishing_vessel_name = Name
  )
```

Now I want to find out all the companies that own these fishing vessels

```{r}
unique(fishing_vessel$company)
```

From the result above I see "SouthSeafood Express Corp" is listed, now I want to isolate all the fishing vessels belong to "SouthSeafood Express Corp".

```{r}
# Filter fishing vessels owned by "SouthSeafood Express Corp"
southseafood_fishing_vessels <- fishing_vessel %>%
  filter(company == "SouthSeafood Express Corp")
print(southseafood_fishing_vessels)
```

So the vessels belong to "SouthSeafood Express Corp" are

-   Snapper Snatcher (snappersnatcher7be)

-   Roach Robber (roachrobberdb6)

After identifying the name of the fishing vessels belong to "SouthSeafood Express Corp", I need to check whether this information is also contained in the mc2_edges_cleaned dataframe.

```{r}
# Check if specific values are in the source column
values_exist <- c("snappersnatcher7be", "roachrobberdb6") %in% mc2_edges_cleaned$source

# Print results
print(values_exist)

```

The output \[1\] TRUE TRUE indicates that both identifiers "snappersnatcher7be" and "roachrobberdb6" are present in the source column of mc2_edges_cleaned dataframe.

The next steps will involve deeper analysis and visualization to understand the activities and patterns associated with these vessels.

```{r}
# Extract relevant data for the specified vessels
southseafood_activities <- mc2_edges_cleaned %>%
  filter(source %in% c("snappersnatcher7be", "roachrobberdb6")) 

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}
# Filter cargo vessels and select specific columns with renaming
cargo_vessel <- mc2_nodes_cleaned %>%
  filter(type %in% c("Entity.Vessel.CargoVessel")) %>%
  select(
    vessel_type = type,
    cargo_vessel_id = id,
    cargo_vessel_name = Name,
    company
  )
```

```{r}
unique(fishing_vessel$company)
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

### Further Data Subsetting and Renaming

#### Creating Subset Data

```{r}
transponderping <- subset(mc2_edges_cleaned, event3 == "TransponderPing")
```

Creates subsets of data for different types of events: transponder pings, transactions, and harbor reports, facilitating focused analysis.

```{r}
transponderping <- subset(mc2_edges_cleaned, event3 == "TransponderPing")
transaction <- subset(mc2_edges_cleaned, event2 == "Transaction")
harbor_report <- subset(mc2_edges_cleaned,  event2 == "HarborReport")
```

```{r}
mc2_nodes_type_counts <- mc2_nodes %>%
  group_by(type) %>%
  summarise(count = n())

# Display the result
print(mc2_nodes_type_counts)
```

```{r}
mc2_nodes_name_counts <- mc2_nodes %>%
  group_by(name) %>%
  summarise(count = n())

# Display the result
print(mc2_nodes_name_counts)
```

```{r}

```

```{r}

```
