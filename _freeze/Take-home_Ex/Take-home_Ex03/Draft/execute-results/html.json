{
  "hash": "5ca950f40d12e282e65692aa33173b72",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Take-home Exercise 3\"\nauthor: \"Arya Siahaan\"\ndate: \"May 15, 2024\"\ndate-modified: \"June 9, 2024\"\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  freeze: true\n---\n\n\n##### Question 1\n\nFishEye analysts have long wanted to better understand the flow of commercially caught fish through Oceanus’s many ports. But as they were loading data into CatchNet, they discovered they had purchased the wrong port records. They wanted to get the ship off-load records, but they instead got the port-exit records (essentially trucks/trains leaving the port area). Port exit records do not include which vessel that delivered the products. Given this limitation, develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?\n\n##### Question 3\n\nTo support further Fisheye investigations, develop visual analytics workflows that allow you to discover other vessels engaging in behaviors similar to SouthSeafood Express Corp’s illegal activities? Provide visual evidence of the similarities.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, jsonlite, igraph, \n               tidygraph, ggraph, skimr,\n               lubridate, ggplot2, DataExplorer) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmc2_data <- fromJSON(\"data/mc2.json\")\n```\n:::\n\n\n## Data Preparation\n\n### Wrangling and tidying edges\n\n#### Extracting edges\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Wrangling and tidying edges\nmc2_edges <- as_tibble(mc2_data$links) %>% distinct()\n# Converts the date columns to POSIXct datetime format using the as_datetime function from the lubridate package, then display it with  glimpse() to confirm if the process have been performed correctly.\nmc2_edges <- mc2_edges %>%\n  mutate(date = as_datetime(date), time = as_datetime(time)) \nglimpse(mc2_edges)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 271,643\nColumns: 17\n$ type                <chr> \"Event.TransportEvent.TransponderPing\", \"Event.Tra…\n$ time                <dttm> 2035-09-16 04:06:48, 2035-09-20 05:21:33, 2035-09…\n$ dwell               <dbl> 115074.79, 412706.32, 286092.88, 327623.95, 243225…\n$ `_last_edited_by`   <chr> \"Olokun Daramola\", \"Melinda Manning\", \"Olokun Dara…\n$ `_date_added`       <chr> \"2035-09-16T00:59:46.300100\", \"2035-09-22T02:37:37…\n$ `_last_edited_date` <chr> \"2035-09-16T00:59:46.300100\", \"2035-09-22T02:37:37…\n$ `_raw_source`       <chr> \"Oceanus Vessel Locator System\", \"Oceanus Vessel L…\n$ `_algorithm`        <chr> \"OVLS-Catch&Hook\", \"OVLS-Catch&Hook\", \"OVLS-Catch&…\n$ source              <chr> \"City of Haacklee\", \"City of Haacklee\", \"City of H…\n$ target              <chr> \"perchplundererbc0\", \"perchplundererbc0\", \"perchpl…\n$ key                 <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7,…\n$ date                <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ data_author         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ aphorism            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ holiday_greeting    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wisdom              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `saying of the sea` <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n```\n\n\n:::\n:::\n\n\nThe code above converts the 'links' part of the dataset into a tibble and removes duplicates. It then converts date and time information into proper datetime formats using lubridate, and extracts just the date to a new column.\n\n#### Splitting and Tidying the 'type' Column\n\n\n::: {.cell}\n\n```{.r .cell-code}\nword_list <- strsplit(mc2_edges$type, \"\\\\.\")\nmax_elements <- max(lengths(word_list)) #to find the maximum number of elements in any split\nword_list_padded <- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x)))) #to pad shorter splits with NA values to make them all the same length.\nword_df <- do.call(rbind, word_list_padded)\ncolnames(word_df) <- paste0(\"event\", 1:max_elements)\n\n# Since the output above is a matrix, the code chunk below is used to convert word_df into a tibble data.frame.\nword_df <- as_tibble(word_df) %>%\n  select(event2, event3)\n\n\n# The code chunk below appends the extracted columns back to mc2_edges tibble data.frame\nmc2_edges <- mc2_edges %>%\n  cbind(word_df)\n```\n:::\n\n\nThis code splits the 'type' column into multiple components, pads shorter entries with NAs, and integrates them back into the mc2_edges dataframe as new columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(mc2_edges)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 271,643\nColumns: 19\n$ type                <chr> \"Event.TransportEvent.TransponderPing\", \"Event.Tra…\n$ time                <dttm> 2035-09-16 04:06:48, 2035-09-20 05:21:33, 2035-09…\n$ dwell               <dbl> 115074.79, 412706.32, 286092.88, 327623.95, 243225…\n$ `_last_edited_by`   <chr> \"Olokun Daramola\", \"Melinda Manning\", \"Olokun Dara…\n$ `_date_added`       <chr> \"2035-09-16T00:59:46.300100\", \"2035-09-22T02:37:37…\n$ `_last_edited_date` <chr> \"2035-09-16T00:59:46.300100\", \"2035-09-22T02:37:37…\n$ `_raw_source`       <chr> \"Oceanus Vessel Locator System\", \"Oceanus Vessel L…\n$ `_algorithm`        <chr> \"OVLS-Catch&Hook\", \"OVLS-Catch&Hook\", \"OVLS-Catch&…\n$ source              <chr> \"City of Haacklee\", \"City of Haacklee\", \"City of H…\n$ target              <chr> \"perchplundererbc0\", \"perchplundererbc0\", \"perchpl…\n$ key                 <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7,…\n$ date                <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ data_author         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ aphorism            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ holiday_greeting    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wisdom              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `saying of the sea` <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ event2              <chr> \"TransportEvent\", \"TransportEvent\", \"TransportEven…\n$ event3              <chr> \"TransponderPing\", \"TransponderPing\", \"Transponder…\n```\n\n\n:::\n:::\n\n\n\n\nAfter cleaning and preparing mc2_edges dataframe, I want to understand how the newly formed structure looks like, lets use the DataExplorer package to visualize it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate and display the data structure plot\nplot_str(mc2_edges)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot introduction of the data\nplot_intro(mc2_edges, title = \"Introduction of mc2_edges Data\")\n```\n\n::: {.cell-output-display}\n![](Draft_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\nLet's find out the missing values in mc2_edges data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot missing values\nplot_missing(mc2_edges, title = \"Missing Values in mc2_edges Data\")\n```\n\n::: {.cell-output-display}\n![](Draft_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\nLet see what are all the values contained in the categorical column in mc2_edges data along with their frequency\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot bar charts for all categorical columns\n# This function automatically handles multiple categorical columns\nplot_bar(mc2_edges, maxcat = 50, title = \"Bar Plots for Categorical Columns in mc2_edges Data\")\n```\n\n::: {.cell-output-display}\n![](Draft_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nLet see the values contained in the numerical column in mc2_edges data along with their frequency\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot histograms for numerical columns\nplot_histogram(mc2_edges, title = \"Histograms for Numerical Columns in mc2_edges Data\")\n```\n\n::: {.cell-output-display}\n![](Draft_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate a Data Explorer report\ncreate_report(mc2_edges, output_file = \"DataExplorer_Report.html\", output_dir = getwd(), report_title = \"EDA Report for mc2_edges\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  |                                           \n  |                                     |   0%\n  |                                           \n  |.                                    |   2%                                 \n  |                                           \n  |..                                   |   5% [global_options]                \n  |                                           \n  |...                                  |   7%                                 \n  |                                           \n  |....                                 |  10% [introduce]                     \n  |                                           \n  |....                                 |  12%                                 \n  |                                           \n  |.....                                |  14% [plot_intro]                    \n  |                                           \n  |......                               |  17%                                 \n  |                                           \n  |.......                              |  19% [data_structure]                \n  |                                           \n  |........                             |  21%                                 \n  |                                           \n  |.........                            |  24% [missing_profile]               \n  |                                           \n  |..........                           |  26%                                 \n  |                                           \n  |...........                          |  29% [univariate_distribution_header]\n  |                                           \n  |...........                          |  31%                                 \n  |                                           \n  |............                         |  33% [plot_histogram]                \n  |                                           \n  |.............                        |  36%                                 \n  |                                           \n  |..............                       |  38% [plot_density]                  \n  |                                           \n  |...............                      |  40%                                 \n  |                                           \n  |................                     |  43% [plot_frequency_bar]            \n  |                                           \n  |.................                    |  45%                                 \n  |                                           \n  |..................                   |  48% [plot_response_bar]             \n  |                                           \n  |..................                   |  50%                                 \n  |                                           \n  |...................                  |  52% [plot_with_bar]                 \n  |                                           \n  |....................                 |  55%                                 \n  |                                           \n  |.....................                |  57% [plot_normal_qq]                \n  |                                           \n  |......................               |  60%                                 \n  |                                           \n  |.......................              |  62% [plot_response_qq]              \n  |                                           \n  |........................             |  64%                                 \n  |                                           \n  |.........................            |  67% [plot_by_qq]                    \n  |                                           \n  |..........................           |  69%                                 \n  |                                           \n  |..........................           |  71% [correlation_analysis]          \n  |                                           \n  |...........................          |  74%                                 \n  |                                           \n  |............................         |  76% [principal_component_analysis]  \n  |                                           \n  |.............................        |  79%                                 \n  |                                           \n  |..............................       |  81% [bivariate_distribution_header] \n  |                                           \n  |...............................      |  83%                                 \n  |                                           \n  |................................     |  86% [plot_response_boxplot]         \n  |                                           \n  |.................................    |  88%                                 \n  |                                           \n  |.................................    |  90% [plot_by_boxplot]               \n  |                                           \n  |..................................   |  93%                                 \n  |                                           \n  |...................................  |  95% [plot_response_scatterplot]     \n  |                                           \n  |.................................... |  98%                                 \n  |                                           \n  |.....................................| 100% [plot_by_scatterplot]           \n                                                                                                                           \n\"C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/pandoc\" +RTS -K512m -RTS \"C:\\aryasiahaan\\ISSS608-VAA\\Take-home_Ex\\Take-home_Ex03\\report.knit.md\" --to html4 --from markdown+autolink_bare_uris+tex_math_single_backslash --output pandoc257c31e663e9.html --lua-filter \"C:\\R-4.4.0\\library\\rmarkdown\\rmarkdown\\lua\\pagebreak.lua\" --lua-filter \"C:\\R-4.4.0\\library\\rmarkdown\\rmarkdown\\lua\\latex-div.lua\" --embed-resources --standalone --variable bs3=TRUE --section-divs --table-of-contents --toc-depth 6 --template \"C:\\R-4.4.0\\library\\rmarkdown\\rmd\\h\\default.html\" --no-highlight --variable highlightjs=1 --variable theme=yeti --mathjax --variable \"mathjax-url=https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\" --include-in-header \"C:\\Users\\asiah\\AppData\\Local\\Temp\\RtmpcReCM2\\rmarkdown-str257c6a463497.html\" \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n```         \n# Create a horizontal bar plot to visualize the distribution of the `event2` column\nggplot(mc2_edges, aes(x = event2)) +\n  geom_bar() +\n  coord_flip() +  # Flip the coordinates to make the bars horizontal\n  labs(title = \"Distribution of `event2` Column\",\n       x = \"Count\",\n       y = \"Event Type\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(size = 10),\n    axis.text.y = element_text(size = 10),\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12)\n  ) +\n  scale_y_continuous(labels = scales::comma)  # Format y-axis labels to comma-separated numbers\n```\n\n```         \n# Create a summary table showing the distribution of the `event2` column\nevent2_summary <- mc2_edges %>%\n  group_by(event2) %>%\n  summarize(\n    Count = n(),\n    Percentage = n() / nrow(mc2_edges) * 100\n  ) %>%\n  arrange(desc(Count))\n\n# Display the summary table\nkable(event2_summary, caption = \"Distribution of `event2` Column\")\n```\n\n### Wrangling and tidying nodes\n\n#### Extracting Nodes and Removing Duplicates\n\n```         \nmc2_nodes <- as_tibble(mc2_data$nodes) %>%\n  distinct()\nglimpse(mc2_nodes)\n```\n\nThis converts the nodes data to a tibble and removes duplicate rows, then displays the structure of the data using glimpse().\n\nI plan to make use of the date column, but since it is in character format, I will convert it first into date format using lubridate package and glimpse it again to verify the changes.\n\n```         \nmc2_nodes <- mc2_nodes %>%\n  mutate(date = as_date(date))\nglimpse(mc2_nodes)\n```\n\nFrom the table above, two more additional data issues can be observed. They are:\n\nThe values in Activities and fish_species_present fields are in list data type, which will affect the ability to process and to analyse the data. As shown in the screenshot below, some values in the Activities field are not ready to be analyse without further tidying (i.e. removing c(““)).\n\nTidying text field In the code chunk below, mutate() of dplyr and gsub() of Base R are used to perform the data tidying task.\n\nThis cleans up the Activities and fish_species_present columns by removing unnecessary characters.\n\n```         \nmc2_nodes <- mc2_nodes %>%\n  mutate(Activities = gsub(\"c[(]\", \"\", Activities)) %>% \n  mutate(Activities = gsub(\"\\\"\", \"\", Activities)) %>%\n  mutate(Activities = gsub(\"[)]\", \"\", Activities)) \n\nmc2_nodes <- mc2_nodes %>%\n  mutate(fish_species_present = gsub(\"c[(]\", \"\", fish_species_present)) %>% \n  mutate(fish_species_present = gsub(\"\\\"\", \"\", fish_species_present)) %>%\n  mutate(fish_species_present = gsub(\"[)]\", \"\", fish_species_present)) \n```\n\n```         \ncreate_report(mc2_nodes)\n```\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n```         \n# Function to get distinct values for each column and prepare data for plotting\nprepare_distinct_values_data <- function(data_frame) {\n  distinct_values <- lapply(data_frame, unique)\n  distinct_counts <- sapply(distinct_values, length)\n  distinct_values_df <- data.frame(\n    Column = names(distinct_values),\n    Number_of_Distinct_Values = distinct_counts,\n    Sample_Distinct_Values = sapply(distinct_values, function(x) paste(head(x, 10), collapse = \", \"))\n  )\n  \n  # Create a long format data frame for plotting\n  plot_data <- data.frame(\n    Column = rep(names(distinct_values), times = sapply(distinct_values, length)),\n    Value = unlist(distinct_values),\n    stringsAsFactors = FALSE\n  )\n  \n  return(list(distinct_values_df = distinct_values_df, plot_data = plot_data))\n}\n\n# Get distinct values for each column in mc2_edges\ndata <- prepare_distinct_values_data(mc2_edges)\ndistinct_values_df <- data$distinct_values_df\nplot_data <- data$plot_data\n\n# Display the summary table\nprint(distinct_values_df)\n\n# Plot distinct values for each column\nggplot(plot_data, aes(x = Value)) +\n  geom_bar() +\n  facet_wrap(~ Column, scales = \"free\", ncol = 2) +\n  labs(title = \"Distinct Values in Each Column\", x = \"Value\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n```\n\n```         \nmc2_edges_list <- list(mc2_edges)\nplot_str(mc2_edges_list)\n```\n\n```         \nmc2_nodes_list <- list(mc2_nodes)\nplot_str(mc2_nodes_list)\n```\n\n```         \ncolnames(mc2_edges)\n```\n\n```         \ncolnames(mc2_nodes)\n```\n\n```         \nExpData(data=mc2_edges, type=1) # For summary statistics\n```\n\n```         \nExpData(data=mc2_edges, type=2) # For visualizations\n```\n\n### Further Data Subsetting and Renaming\n\n#### Creating Subset Data\n\n```         \ntransponderping <- subset(mc2_edges_cleaned, event3 == \"TransponderPing\")\ntransaction <- subset(mc2_edges_cleaned, event2 == \"Transaction\")\nharbor_report <- subset(mc2_edges_cleaned,  event2 == \"HarborReport\")\n```\n\nCreates subsets of data for different types of events: transponder pings, transactions, and harbor reports, facilitating focused analysis.\n\n#### Handling Fish Data\n\n```         \nfish <- subset(mc2_nodes_cleaned,  mc2_nodes_cleaned$type == \"Entity.Commodity.Fish\") %>%\n  select_if(~ !any(is.na(.))) %>% \n  select(-c(`type`, `Activities`, `fish_species_present`)) %>%\n  rename(fish_species = name, \n         fish_id = id)\n```\n\n#### Subsetting City Data\n\n```         \ncity <- subset(mc2_nodes_cleaned,  mc2_nodes_cleaned$type == \"Entity.Location.City\") %>%\n  select_if(~ !any(is.na(.))) %>%\n  select(-c(`type`, `fish_species_present`)) %>%\n  rename(city_name = Name, \n         city_id = id)\n```\n\nThis code processes the city-related data by filtering cities, excluding any incomplete records, and renaming fields to reflect their content more accurately (city names and IDs).\n\n#### Subsetting Point Location\n\n```         \npoint <- subset(mc2_nodes_cleaned,  mc2_nodes_cleaned$type == \"Entity.Location.Point\") %>%\n  select_if(~ !any(is.na(.))) %>%\n  select(-c(`kind`, `fish_species_present`)) %>%\n  rename(point_name = Name, \n         point_id = id)\n```\n\nThis snippet focuses on geographical points, cleaning up the data by removing unnecessary columns and renaming the remaining columns to make them more intuitive (point names and IDs).\n\n#### Subsetting Region Data\n\n```         \nregion <- subset(mc2_nodes_cleaned,  mc2_nodes_cleaned$type == \"Entity.Location.Region\") %>%\n  select_if(~ !any(is.na(.))) %>%\n  select(-c(`type`, `Description`)) %>%\n  rename(region_name = Name, \n         region_id = id, \n         region_kind = kind)\n```\n\nExtracts and cleans data related to geographic regions, ensuring all entries are complete and renaming columns to better describe their contents, including region type.\n\n#### Subsetting Delivery Report Data\n\n```         \ndelivery_report <- subset(mc2_nodes_cleaned,  mc2_nodes_cleaned$type == \"Entity.Document.DeliveryReport\") %>%\n  select_if(~ !any(is.na(.))) %>%\n  rename(delivery_date = date,\n         cargo_id = id) %>%\n  select(-c(`type`, `Activities`, `fish_species_present`)) \n```\n\n### Vessel-Specific Data Preparation\n\n#### Fishing Vessel Data\n\n```         \n# Load and clean the fishing vessel data\nfishing_vessel <- mc2_nodes_cleaned %>%\n  filter(grepl(\"Entity.Vessel.FishingVessel\", type)) %>%\n  mutate(vessel_type = \"Fishing\") %>%\n  mutate(company = ifelse(is.na(company), \"Unknown\", company)) %>%\n  select(-c(type, Activities, fish_species_present, Description, kind, name, qty_tons, date)) %>%\n  rename(fishing_vessel_id = id, fishing_vessel_name = Name)\n```\n\nIsolates data concerning fishing vessels, classifying them appropriately and ensuring all records are complete. It renames columns for greater clarity and focuses on identifying and naming the vessels.\n\n#### Cargo Vessel Data\n\n```         \n# Load and clean the cargo vessel data\ncargo_vessel <- mc2_nodes_cleaned %>%\n  filter(grepl(\"Entity.Vessel.CargoVessel\", type)) %>%\n  mutate(vessel_type = \"Cargo\") %>%\n  mutate(company = ifelse(is.na(company), \"Unknown\", company)) %>%\n  select(-c(type, Activities, fish_species_present, Description, kind, name, qty_tons, date)) %>%\n  rename(cargo_vessel_id = id, cargo_vessel_name = Name)\n```\n\nSimilar to the fishing vessels, this snippet deals with cargo vessels, tidying the data and ensuring that the vessel type and company fields are correctly populated.\n\n### Transaction and Harbor Report Data Processing\n\n#### Transaction Data\n\n```         \n# Load and clean the transaction data\ntransactions_cleaned <- mc2_edges_cleaned %>%\n  filter(event2 == \"Transaction\") %>%\n  select(date, source, target) %>%\n  rename(cargo_id = source)\n```\n\nFocuses on transaction data from the edges, renaming columns to better represent the transaction's nature—linking transactions via cargo IDs.\n\n#### Harbor Report Data\n\n```         \n# Load and clean the harbor report data\nharbor_report_cleaned <- mc2_edges_cleaned %>%\n  filter(event2 == \"HarborReport\") %>%\n  select(date, source, target) %>%\n  rename(vessel_id = source, port = target)\n```\n\nCleans and prepares harbor report data, linking reports to specific vessels and ports, and renaming columns for better readability and further analysis.\n\n#### Dropping Unnecessary Columns\n\n```         \nmc2_edges_cleaned <- mc2_edges %>%\n  select(-c(`_last_edited_by`, `_date_added`, `_last_edited_date`, `_raw_source`, `_algorithm`, `key`, `type`, `data_author`, `aphorism`, `holiday_greeting`, `wisdom`, `saying of the sea`))\n\nglimpse(mc2_edges_cleaned)\n```\n\nRemoves unnecessary columns from the dataset that are not needed for analysis, cleaning up the data. Glimpse() is then used to display the structure of the data.\n\n#### Dropping unnecessary Columns\n\n```         \nmc2_nodes_cleaned <- mc2_nodes_cleaned %>%\n  select(-c(`_last_edited_by`, `_date_added`, `_last_edited_date`, `_raw_source`, `_algorithm`, `style`))\nglimpse(mc2_nodes_cleaned)\n```\n\nRemoves additional unneeded columns from the nodes data frame.\n",
    "supporting": [
      "Draft_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}