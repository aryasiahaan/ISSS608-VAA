[
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "There are two major residential property markets in Singapore, namely public and private housing. Public housing aims to meet the basic needs of the general public with a monthly household income of less than or equal to S$14,000. For families with a monthly household income of more than S$14,000, they need to turn to the private residential market.\n\n\n\nIn this task, I am to assume the role of a graphical editor of a median company. I have been requested to prepare a minimum of two and a maximum of three data visualisations to reveal the private residential market and its sub-markets in Singapore for the 1st quarter of 2024."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "There are two major residential property markets in Singapore, namely public and private housing. Public housing aims to meet the basic needs of the general public with a monthly household income of less than or equal to S$14,000. For families with a monthly household income of more than S$14,000, they need to turn to the private residential market."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-task",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "In this task, I am to assume the role of a graphical editor of a median company. I have been requested to prepare a minimum of two and a maximum of three data visualisations to reveal the private residential market and its sub-markets in Singapore for the 1st quarter of 2024."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background",
    "title": "Take-home Exercise 1",
    "section": "1.1 Background",
    "text": "1.1 Background"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "title": "Take-home Exercise 1",
    "section": "1.2 The Data",
    "text": "1.2 The Data"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-task-1",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-task-1",
    "title": "Take-home Exercise 1",
    "section": "1.3 The Task",
    "text": "1.3 The Task"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "In the code chunk below, p_load() of pacman package is used to load tidyverse family of packages.\n\npacman::p_load(tidyverse)\n\n\nrealis &lt;- read_csv(\"data/realis2019.csv\")\n\n\nggplot(data = realis,\n       aes(x = `Unit Price ($ psm)`)) +\n  geom_histogram()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "In the code chunk below, p_load() of pacman package is used to load tidyverse family of packages.\n\npacman::p_load(tidyverse)\n\n\nrealis &lt;- read_csv(\"data/realis2019.csv\")\n\n\nggplot(data = realis,\n       aes(x = `Unit Price ($ psm)`)) +\n  geom_histogram()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In this chapter, you will learn the basic principles and essential components of ggplot2. At the same time, you will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics. By then end of this chapter you will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics.\n\n\n\n\n\nBefore we get started, it is important for us to ensure that the required R packages have been installed. If yes, we will load the R packages. If they have yet to be installed, we will install the R packages and load them onto R environment.\nThe code chunk below use p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk on the right assumes that you already have pacman package installed. If not, please go ahead install pacman first.\n\n\n\npacman::p_load(tidyverse)\n\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\n\n\n\n\n is an R package for declaratively creating data-driven graphics based on The Grammar of Graphics\n\nIt is also part of the tidyverse family specially designed for visual exploration and communication.\n\n\nFor more detail, visit ggplot2 link.\n\n\n\nFirst, let us compare how R Graphics, the core graphical functions of Base R and ggplot plot a simple histogram.\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\nAs you can see that the code chunk is relatively simple if R Graphics is used. Then, the question is why ggplot2 is recommended?\nAs pointed out by Hadley Wickham\n\n\n\n\n\n\nImportant\n\n\n\nThe transferable skills from ggplot2 are not the idiosyncrasies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive.\n\n\n\n\n\n\nBefore we getting started using ggplot2, it is important for us to understand the principles of Grammer of Graphics.\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\nWhat is a statistical graphic?\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. Figure below shows the seven grammars of ggplot2.\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background.\n\n\n\n\n\nLet us call the ggplot() function using the code chunk on the right.\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\n\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\nCode chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data,\naes(x= MATHS))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\nTip with Title\n\n\n\nThis is an example of a callout with a title.\n\n\n\n\n\n\n\n\nExpand To Learn About Collapse\n\n\n\n\n\nThis is an example of a ‘folded’ caution callout that can be expanded by the user. You can use collapse=\"true\" to collapse it by default or collapse=\"false\" to make a collapsible callout that is expanded by default.\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x=RACE)) +\ngeom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x = MATHS)) +\ngeom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x = MATHS)) +\ngeom_dotplot(binwidth=2.5,\ndotsize = 0.5) +\nscale_y_continuous(NULL,\nbreaks = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x = MATHS)) +\ngeom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS)) +\ngeom_histogram(bins=20,\ncolor=\"black\",\nfill=\"light blue\")\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS,\nfill = GENDER)) +\ngeom_histogram(bins=20,\ncolor=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x = MATHS)) +\ngeom_density()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x = MATHS,\ncolour = GENDER)) +\ngeom_density()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS,\nx= GENDER)) +\ngeom_boxplot()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS,\nx= GENDER)) +\ngeom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS,\nx= GENDER)) +\ngeom_violin()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS,\ny=ENGLISH)) +\ngeom_point()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS,\nx= GENDER)) +\ngeom_boxplot() +\ngeom_point(position=\"jitter\",\nsize = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS, x= GENDER)) +\ngeom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS, x= GENDER)) +\ngeom_boxplot() +\nstat_summary(geom = \"point\",\nfun.y=\"mean\",\ncolour =\"red\",\nsize=4)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS, x= GENDER)) +\ngeom_boxplot() +\ngeom_point(stat=\"summary\",\nfun.y=\"mean\",\ncolour =\"red\",\nsize=4)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS, y=ENGLISH)) +\ngeom_point() +\ngeom_smooth(size=0.5)\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS,\ny=ENGLISH)) +\ngeom_point() +\ngeom_smooth(method=lm,\nsize=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS)) +\ngeom_histogram(bins=20) +\nfacet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS)) +\ngeom_histogram(bins=20) +\nfacet_grid(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x=RACE)) +\ngeom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x=RACE)) +\ngeom_bar() +\ncoord_flip()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS, y=ENGLISH)) +\ngeom_point() +\ngeom_smooth(method=lm, size=0.5)\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS, y=ENGLISH)) +\ngeom_point() +\ngeom_smooth(method=lm,\nsize=0.5) +\ncoord_cartesian(xlim=c(0,100),\nylim=c(0,100))\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x=RACE)) +\ngeom_bar() +\ncoord_flip() +\ntheme_gray()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x=RACE)) +\ngeom_bar() +\ncoord_flip() +\ntheme_classic()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x=RACE)) +\ngeom_bar() +\ncoord_flip() +\ntheme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below use p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Let us call the ggplot() function using the code chunk on the right.\n\nggplot(data=exam_data)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\nCode chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data,\naes(x= MATHS))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\nTip with Title\n\n\n\nThis is an example of a callout with a title.\n\n\n\n\n\n\n\n\nExpand To Learn About Collapse\n\n\n\n\n\nThis is an example of a ‘folded’ caution callout that can be expanded by the user. You can use collapse=\"true\" to collapse it by default or collapse=\"false\" to make a collapsible callout that is expanded by default.\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x=RACE)) +\ngeom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x = MATHS)) +\ngeom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x = MATHS)) +\ngeom_dotplot(binwidth=2.5,\ndotsize = 0.5) +\nscale_y_continuous(NULL,\nbreaks = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x = MATHS)) +\ngeom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS)) +\ngeom_histogram(bins=20,\ncolor=\"black\",\nfill=\"light blue\")\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS,\nfill = GENDER)) +\ngeom_histogram(bins=20,\ncolor=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x = MATHS)) +\ngeom_density()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x = MATHS,\ncolour = GENDER)) +\ngeom_density()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS,\nx= GENDER)) +\ngeom_boxplot()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS,\nx= GENDER)) +\ngeom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS,\nx= GENDER)) +\ngeom_violin()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS,\ny=ENGLISH)) +\ngeom_point()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS,\nx= GENDER)) +\ngeom_boxplot() +\ngeom_point(position=\"jitter\",\nsize = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS, x= GENDER)) +\ngeom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS, x= GENDER)) +\ngeom_boxplot() +\nstat_summary(geom = \"point\",\nfun.y=\"mean\",\ncolour =\"red\",\nsize=4)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(y = MATHS, x= GENDER)) +\ngeom_boxplot() +\ngeom_point(stat=\"summary\",\nfun.y=\"mean\",\ncolour =\"red\",\nsize=4)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS, y=ENGLISH)) +\ngeom_point() +\ngeom_smooth(size=0.5)\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS,\ny=ENGLISH)) +\ngeom_point() +\ngeom_smooth(method=lm,\nsize=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS)) +\ngeom_histogram(bins=20) +\nfacet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS)) +\ngeom_histogram(bins=20) +\nfacet_grid(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x=RACE)) +\ngeom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x=RACE)) +\ngeom_bar() +\ncoord_flip()\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS, y=ENGLISH)) +\ngeom_point() +\ngeom_smooth(method=lm, size=0.5)\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x= MATHS, y=ENGLISH)) +\ngeom_point() +\ngeom_smooth(method=lm,\nsize=0.5) +\ncoord_cartesian(xlim=c(0,100),\nylim=c(0,100))\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x=RACE)) +\ngeom_bar() +\ncoord_flip() +\ntheme_gray()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x=RACE)) +\ngeom_bar() +\ncoord_flip() +\ntheme_classic()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\naes(x=RACE)) +\ngeom_bar() +\ncoord_flip() +\ntheme_minimal()"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this chapter, you will be introduced to several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, you will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package.\n\n\n\n\n\n\nIn this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork,\n               ggthemes, hrbrthemes,\n               tidyverse)\n\npackage 'Rcpp' successfully unpacked and MD5 sums checked\npackage 'ggrepel' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpaAERmN\\downloaded_packages\npackage 'patchwork' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpaAERmN\\downloaded_packages\npackage 'ggthemes' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpaAERmN\\downloaded_packages\npackage 'triebeard' successfully unpacked and MD5 sums checked\npackage 'httpuv' successfully unpacked and MD5 sums checked\npackage 'xtable' successfully unpacked and MD5 sums checked\npackage 'sourcetools' successfully unpacked and MD5 sums checked\npackage 'later' successfully unpacked and MD5 sums checked\npackage 'promises' successfully unpacked and MD5 sums checked\npackage 'commonmark' successfully unpacked and MD5 sums checked\npackage 'urltools' successfully unpacked and MD5 sums checked\npackage 'httpcode' successfully unpacked and MD5 sums checked\npackage 'shiny' successfully unpacked and MD5 sums checked\npackage 'crul' successfully unpacked and MD5 sums checked\npackage 'fontBitstreamVera' successfully unpacked and MD5 sums checked\npackage 'fontLiberation' successfully unpacked and MD5 sums checked\npackage 'extrafontdb' successfully unpacked and MD5 sums checked\npackage 'Rttf2pt1' successfully unpacked and MD5 sums checked\npackage 'gfonts' successfully unpacked and MD5 sums checked\npackage 'fontquiver' successfully unpacked and MD5 sums checked\npackage 'extrafont' successfully unpacked and MD5 sums checked\npackage 'gdtools' successfully unpacked and MD5 sums checked\npackage 'hrbrthemes' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpaAERmN\\downloaded_packages\n\n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE.\n\n\n\n\n\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#overview",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this chapter, you will be introduced to several ggplot2 extensions for creating more elegant and effective statistical graphics. By the end of this exercise, you will be able to:\n\ncontrol the placement of annotation on a graph by using functions provided in ggrepel package,\ncreate professional publication quality figure by using functions provided in ggthemes and hrbrthemes packages,\nplot composite figure by combining ggplot2 graphs by using patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "In this exercise, beside tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork,\n               ggthemes, hrbrthemes,\n               tidyverse)\n\npackage 'Rcpp' successfully unpacked and MD5 sums checked\npackage 'ggrepel' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpaAERmN\\downloaded_packages\npackage 'patchwork' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpaAERmN\\downloaded_packages\npackage 'ggthemes' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpaAERmN\\downloaded_packages\npackage 'triebeard' successfully unpacked and MD5 sums checked\npackage 'httpuv' successfully unpacked and MD5 sums checked\npackage 'xtable' successfully unpacked and MD5 sums checked\npackage 'sourcetools' successfully unpacked and MD5 sums checked\npackage 'later' successfully unpacked and MD5 sums checked\npackage 'promises' successfully unpacked and MD5 sums checked\npackage 'commonmark' successfully unpacked and MD5 sums checked\npackage 'urltools' successfully unpacked and MD5 sums checked\npackage 'httpcode' successfully unpacked and MD5 sums checked\npackage 'shiny' successfully unpacked and MD5 sums checked\npackage 'crul' successfully unpacked and MD5 sums checked\npackage 'fontBitstreamVera' successfully unpacked and MD5 sums checked\npackage 'fontLiberation' successfully unpacked and MD5 sums checked\npackage 'extrafontdb' successfully unpacked and MD5 sums checked\npackage 'Rttf2pt1' successfully unpacked and MD5 sums checked\npackage 'gfonts' successfully unpacked and MD5 sums checked\npackage 'fontquiver' successfully unpacked and MD5 sums checked\npackage 'extrafont' successfully unpacked and MD5 sums checked\npackage 'gdtools' successfully unpacked and MD5 sums checked\npackage 'hrbrthemes' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpaAERmN\\downloaded_packages\n\n\n\n\n\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on Exercise 2",
    "section": "",
    "text": "One of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608 Visual Analytics and Applications",
    "section": "",
    "text": "Welcome to my portfolio for the ISSS608 Visual Analytics and Applications course, taught by Professor Kam Tin Seong at Singapore Management University. This website showcases a compilation of the exercises and assignments I have undertaken and completed over the duration of the course."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-data-visualisation-beyond-default",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-data-visualisation-beyond-default",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "There are two major residential property market in Singapore, namely public and private housing. Public housing aims to meet the basic need of the general public with monthly household income less than or equal to S$14,000. For families with monthly household income more than S$14,000, they need to turn to the private residential market.\n\n\n\nIn this task, I am to assumed the role of a graphical editor of a median company, I have been requested to prepare a minimum of two and a maximum of three data visualisation to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024.\n\n\n\n\n\nThe following code chunk utilises p_load() function from the pacman package to ensure that the necessary packages are available in the R environment. If the packages are already installed on the computer, p_load() will load them. If they are not installed, it will first install them and then load them into the R environment.\n\npacman::p_load(tidyverse, scales,\n               lubridate, ggrepel, \n               ggthemes, hrbrthemes, \n               patchwork, knitr) \n\n\n\n\nThe Datasets\nThere are 5 datasets that covers from the start of 1st quarter 2023 to the end of the 1st quarter 2024, I decided to load each dataset in separate code chunk for better clarity in understanding the data types\n\n\n\nq1_2023 &lt;- read_csv(\"data/ResidentialTransaction20240308160536.csv\")\n\nRows: 4722 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Project Name, Sale Date, Address, Type of Sale, Type of Area, Nett...\ndbl  (1): Number of Units\nnum  (5): Transacted Price ($), Area (SQFT), Unit Price ($ PSF), Area (SQM),...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(q1_2023)\n\nRows: 4,722\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 20…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\n\n\n\n\nq2_2023 &lt;- read_csv(\"data/ResidentialTransaction20240308160736.csv\")\n\nRows: 6125 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Project Name, Sale Date, Address, Type of Sale, Type of Area, Nett...\ndbl  (1): Number of Units\nnum  (5): Transacted Price ($), Area (SQFT), Unit Price ($ PSF), Area (SQM),...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nq3_2023 &lt;- read_csv(\"data/ResidentialTransaction20240308161009.csv\")\n\nRows: 6206 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Project Name, Sale Date, Address, Type of Sale, Type of Area, Nett...\ndbl  (2): Area (SQM), Number of Units\nnum  (4): Transacted Price ($), Area (SQFT), Unit Price ($ PSF), Unit Price ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs can be seen above, I noticed that in this particular dataset (Quarter 3, Year 2023) the data type for column Area (SQM) is ‘dbl’ (double), while in all the other four datasets the data type for column Area (SQM) is ‘num’ (numeric). As far as I know, R does not differentiate between ‘dbl’ and ‘num’, so in this case I will leave it as ‘dbl’ data type.\n\n\n\n\n\n\nq4_2023 &lt;- read_csv(\"data/ResidentialTransaction20240308161109.csv\")\n\nRows: 4851 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Project Name, Sale Date, Address, Type of Sale, Type of Area, Nett...\ndbl  (1): Number of Units\nnum  (5): Transacted Price ($), Area (SQFT), Unit Price ($ PSF), Area (SQM),...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nq1_2024 &lt;- read_csv(\"data/ResidentialTransaction20240414220633.csv\")\n\nRows: 4902 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Project Name, Sale Date, Address, Type of Sale, Type of Area, Nett...\ndbl  (1): Number of Units\nnum  (5): Transacted Price ($), Area (SQFT), Unit Price ($ PSF), Area (SQM),...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nNote\n\n\n\nI also noticed that the Sale Date column data type format in all of these five datasets are in ‘chr’ (character). I will parse/convert them into date-time format.\n\n\nData will be processed using appropriate tidyverse family of packages. Statistical graphics will be created using ggplot2 and its extensions.\nParsing the Sale Date column into date-time format using ‘lubridate’ package\n\nq1_2023 &lt;- q1_2023 %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`))\n\nq2_2023 &lt;- q2_2023 %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`))\n\nq3_2023 &lt;- q3_2023 %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`))\n\nq4_2023 &lt;- q4_2023 %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`))\n\nq1_2024 &lt;- q1_2024 %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`))\n\nExplanation:\n\nThe mutate() function is used to modify the Sale Date column directly.\n\nSince the column name has a space in it, I need to use backticks to refer to it within the mutate() function.\n\nThe dmy() function from the lubridate package will parse the date strings into actual Date objects.\n\nNext using the code below, I will check and confirmed that the data types have been converted properly.\n\nclass(q1_2023$`Sale Date`)\n\n[1] \"Date\"\n\nclass(q2_2023$`Sale Date`)\n\n[1] \"Date\"\n\nclass(q3_2023$`Sale Date`)\n\n[1] \"Date\"\n\nclass(q4_2023$`Sale Date`)\n\n[1] \"Date\"\n\nclass(q1_2024$`Sale Date`)\n\n[1] \"Date\"\n\n\nStep 5: Merge the Data\nAfter standardizing the data in all five datasets, I will then merge these datasets together using the bind_rows() function from the dplyr package. This function stacks data frames on top of each other, combining them into a single data frame. It’s important that all data frames have the same columns for bind_rows() to work correctly.\n\ncombined_data &lt;- bind_rows(q1_2023, q2_2023, q3_2023, q4_2023, q1_2024)\n\n\n\n\n\n\nAfter merging, it’s good practice to check the combined dataset to ensure everything looks as expected:\n\n# Check the structure of the combined data\nstr(combined_data)\n\ntibble [26,806 × 21] (S3: tbl_df/tbl/data.frame)\n $ Project Name               : chr [1:26806] \"THE REEF AT KING'S DOCK\" \"URBAN TREASURES\" \"NORTH GAIA\" \"NORTH GAIA\" ...\n $ Transacted Price ($)       : num [1:26806] 2317000 1823500 1421112 1258112 1280000 ...\n $ Area (SQFT)                : num [1:26806] 883 883 1076 1033 872 ...\n $ Unit Price ($ PSF)         : num [1:26806] 2625 2066 1320 1218 1468 ...\n $ Sale Date                  : Date[1:26806], format: \"2023-01-01\" \"2023-01-02\" ...\n $ Address                    : chr [1:26806] \"12 HARBOURFRONT AVENUE #05-32\" \"205 JALAN EUNOS #08-02\" \"29 YISHUN CLOSE #08-10\" \"45 YISHUN CLOSE #07-42\" ...\n $ Type of Sale               : chr [1:26806] \"New Sale\" \"New Sale\" \"New Sale\" \"New Sale\" ...\n $ Type of Area               : chr [1:26806] \"Strata\" \"Strata\" \"Strata\" \"Strata\" ...\n $ Area (SQM)                 : num [1:26806] 82 82 100 96 81 ...\n $ Unit Price ($ PSM)         : num [1:26806] 28256 22238 14211 13105 15802 ...\n $ Nett Price($)              : chr [1:26806] \"-\" \"-\" \"-\" \"-\" ...\n $ Property Type              : chr [1:26806] \"Condominium\" \"Condominium\" \"Executive Condominium\" \"Executive Condominium\" ...\n $ Number of Units            : num [1:26806] 1 1 1 1 1 1 1 1 1 1 ...\n $ Tenure                     : chr [1:26806] \"99 yrs from 12/01/2021\" \"Freehold\" \"99 yrs from 15/02/2021\" \"99 yrs from 15/02/2021\" ...\n $ Completion Date            : chr [1:26806] \"Uncompleted\" \"Uncompleted\" \"Uncompleted\" \"Uncompleted\" ...\n $ Purchaser Address Indicator: chr [1:26806] \"HDB\" \"Private\" \"HDB\" \"HDB\" ...\n $ Postal Code                : chr [1:26806] \"097996\" \"419535\" \"269343\" \"269294\" ...\n $ Postal District            : chr [1:26806] \"04\" \"14\" \"27\" \"27\" ...\n $ Postal Sector              : chr [1:26806] \"09\" \"41\" \"26\" \"26\" ...\n $ Planning Region            : chr [1:26806] \"Central Region\" \"East Region\" \"North Region\" \"North Region\" ...\n $ Planning Area              : chr [1:26806] \"Bukit Merah\" \"Bedok\" \"Yishun\" \"Yishun\" ...\n\n# View the first few rows to confirm data looks correct\nhead(combined_data)\n\n# A tibble: 6 × 21\n  `Project Name`       `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n  &lt;chr&gt;                                 &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n1 THE REEF AT KING'S …                2317000          883.                 2625\n2 URBAN TREASURES                     1823500          883.                 2066\n3 NORTH GAIA                          1421112         1076.                 1320\n4 NORTH GAIA                          1258112         1033.                 1218\n5 PARC BOTANNIA                       1280000          872.                 1468\n6 NANYANG PARK                        5870000         3323.                 1767\n# ℹ 17 more variables: `Sale Date` &lt;date&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n# Check for any missing values or anomalies\nsummary(combined_data)\n\n Project Name       Transacted Price ($)  Area (SQFT)       Unit Price ($ PSF)\n Length:26806       Min.   :   440000    Min.   :   322.9   Min.   : 138      \n Class :character   1st Qu.:  1280000    1st Qu.:   721.2   1st Qu.:1384      \n Mode  :character   Median :  1660000    Median :   990.3   Median :1762      \n                    Mean   :  2143286    Mean   :  1191.6   Mean   :1852      \n                    3rd Qu.:  2320000    3rd Qu.:  1302.4   3rd Qu.:2260      \n                    Max.   :392180000    Max.   :144883.4   Max.   :5756      \n                                                                              \n   Sale Date            Address          Type of Sale       Type of Area      \n Min.   :2023-01-01   Length:26806       Length:26806       Length:26806      \n 1st Qu.:2023-04-29   Class :character   Class :character   Class :character  \n Median :2023-07-28   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2023-08-11                                                           \n 3rd Qu.:2023-11-20                                                           \n Max.   :2024-03-31                                                           \n                                                                              \n   Area (SQM)      Unit Price ($ PSM) Nett Price($)      Property Type     \n Min.   :   30.0   Min.   : 1484      Length:26806       Length:26806      \n 1st Qu.:   67.0   1st Qu.:14893      Class :character   Class :character  \n Median :   92.0   Median :18966      Mode  :character   Mode  :character  \n Mean   :  110.5   Mean   :19930                                           \n 3rd Qu.:  121.0   3rd Qu.:24327                                           \n Max.   :13460.0   Max.   :61962                                           \n NA's   :6                                                                 \n Number of Units     Tenure          Completion Date   \n Min.   : 1.000   Length:26806       Length:26806      \n 1st Qu.: 1.000   Class :character   Class :character  \n Median : 1.000   Mode  :character   Mode  :character  \n Mean   : 1.005                                        \n 3rd Qu.: 1.000                                        \n Max.   :60.000                                        \n                                                       \n Purchaser Address Indicator Postal Code        Postal District   \n Length:26806                Length:26806       Length:26806      \n Class :character            Class :character   Class :character  \n Mode  :character            Mode  :character   Mode  :character  \n                                                                  \n                                                                  \n                                                                  \n                                                                  \n Postal Sector      Planning Region    Planning Area     \n Length:26806       Length:26806       Length:26806      \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character  \n                                                         \n                                                         \n                                                         \n                                                         \n\n\n\n\n\nSince I may need to use to use this merged datasets repeatedly, I will save it into a file for easy access in future sessions. I will use ‘write_csv()’ function from the ‘readr’ package (part of the ‘tidyverse’) to write this merged data frame to a CSV file.\n\nwrite_csv(combined_data, \"data/All_ResidentialTransactions_2023-2024.csv\")\n\n\n\n\nNow the data has been consolidated into a single dataframe, it is time to move forward with analysis:\n\nDescriptive Statistics: Summarize the data to get a sense of trends or patterns.\nTime Series Analysis: Analyze changes over time across different quarters.\nVisualizations: Create plots to visualize trends, distributions, and relationships in the data.\n\n\n\n\nAfter all the previous setup and loaded libraries, next is to create the visualization to see the trends in the data.\n\n# Generate a Month-Year field for the x-axis and calculate total sales volume\nmonthly_sales_stats &lt;- combined_data %&gt;%\n  mutate(Month = floor_date(`Sale Date`, unit = \"month\")) %&gt;%\n  group_by(Month) %&gt;%\n  summarise(Total_Sales_Volume = sum(`Number of Units`, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  arrange(Month)\n\n# Calculate the average monthly sales volume\naverage_sales_volume &lt;- mean(monthly_sales_stats$Total_Sales_Volume)\n\n# Create the line chart visualizing monthly sales volume and add the average reference line\nmonthly_sales_line_chart &lt;- ggplot(monthly_sales_stats, aes(x = Month, y = Total_Sales_Volume)) +\n  geom_line(color = \"black\") +  # Line color\n  geom_point(color = \"black\") +  # Point color\n  geom_hline(yintercept = average_sales_volume, linetype = \"dotted\", color = \"red\", size = 1) +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n  theme_minimal() +\n  labs(\n    title = \"Monthly Sales Volume with Average Reference Line\",\n    x = \"Month\",\n    y = \"Total Units Sold\"\n  ) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))  # Rotate the x-axis text for better readability\n\n# Print the plot\nmonthly_sales_line_chart\n\n\n\n\nThe visualisation illustrates the monthly sales volume trend of private housing units from January 2023 to March 2024. The trend shows significant fluctuation throughout the period, with peaks and troughs corresponding to market activity. Notably, there’s a sharp increase in March 2023, suggesting a spike in sales, possibly due to market stimuli or seasonal factors. The overall pattern indicates a resilient market, yet with periods of reticence, potentially reflective of economic events or policy changes. The red dotted line represents the average sales volume across the period, providing a benchmark against which to compare monthly performance. The months above this line saw higher-than-average sales, whereas those below saw fewer transactions, highlighting the varying buyer activity throughout the year.\n\n# Assuming 'combined_data' is your dataframe and has a column 'Property Type'\n# and 'Number of Units' for each transaction\n\n# First, we aggregate the number of units sold by property type\nproperty_type_distribution &lt;- combined_data %&gt;%\n  group_by(`Property Type`) %&gt;%\n  summarise(Transactions = n(), .groups = 'drop')\n\n# Now, we plot the distribution\nproperty_type_chart &lt;- ggplot(property_type_distribution, aes(x = `Property Type`, y = Transactions, fill = `Property Type`)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Property Type Distribution in Singapore Private Residential Market\",\n       x = \"Property Type\",\n       y = \"Number of Transactions\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n# Print the plot\nprint(property_type_chart)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#loading-r-packages",
    "title": "In-class Exercise 2",
    "section": "Loading R packages",
    "text": "Loading R packages\n\npacman::p_load(tidyverse, ggdist, ggridges,\n               colorspace, ggthemes)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution",
    "title": "In-class Exercise 2",
    "section": "Visualising Distribution",
    "text": "Visualising Distribution"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#histogram",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#histogram",
    "title": "In-class Exercise 2",
    "section": "Histogram",
    "text": "Histogram"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution-1",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-distribution-1",
    "title": "In-class Exercise 2",
    "section": "Visualising Distribution",
    "text": "Visualising Distribution"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#probability-density-plot",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#probability-density-plot",
    "title": "In-class Exercise 2",
    "section": "Probability density plot",
    "text": "Probability density plot\n\nThe taskThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam_df,\n       aes(x = ENGLISH)) +\n  geom_density(\n    color = \"#1696d2\",\n    adjust = .65,\n    alpha = .6\n  )\n\n\n\n\nmedian_eng &lt;- median(exam_df\\(ENGLISH) mean_eng &lt;- mean(exam_df\\)ENGLISH) std_eng &lt;_ sd(exam_df$ENGLISH)\nggplot(exam_df, aes(x = ENGLISH)) geom_density( color = “#1696d2”, adjust = .65, alpha = .6) + stat_function( fun = dnorm, args = list(mean = mean_eng, sd = std_eng), col = “grey30”, size = 0.8) + geom_vline( aes(xintercept = mean_eng), colour=“4d5887”, linewidth = 0.6, linetype = “dashed”) + annotate(geom = “text”, x = mean_eng - 8 y = 0.04, label = paste0(“Mean ENGLISH:”, round((mean_eng), 2)), ) ) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#learning-outcome",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "In this chapter, you will learn the basic principles and essential components of ggplot2. At the same time, you will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics. By then end of this chapter you will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Before we get started, it is important for us to ensure that the required R packages have been installed. If yes, we will load the R packages. If they have yet to be installed, we will install the R packages and load them onto R environment.\nThe code chunk below use p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk on the right assumes that you already have pacman package installed. If not, please go ahead install pacman first.\n\n\n\npacman::p_load(tidyverse)\n\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "is an R package for declaratively creating data-driven graphics based on The Grammar of Graphics\n\nIt is also part of the tidyverse family specially designed for visual exploration and communication.\n\n\nFor more detail, visit ggplot2 link.\n\n\n\nFirst, let us compare how R Graphics, the core graphical functions of Base R and ggplot plot a simple histogram.\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\nAs you can see that the code chunk is relatively simple if R Graphics is used. Then, the question is why ggplot2 is recommended?\nAs pointed out by Hadley Wickham\n\n\n\n\n\n\nImportant\n\n\n\nThe transferable skills from ggplot2 are not the idiosyncrasies of plotting syntax, but a powerful way of thinking about visualisation, as a way of mapping between variables and the visual properties of geometric objects that you can perceive."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Before we getting started using ggplot2, it is important for us to understand the principles of Grammer of Graphics.\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\nWhat is a statistical graphic?\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\n\n\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. Figure below shows the seven grammars of ggplot2.\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages.\n\n\n\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(plotly,patchwork, DT, tidyverse) \n\npackage 'lazyeval' successfully unpacked and MD5 sums checked\npackage 'crosstalk' successfully unpacked and MD5 sums checked\npackage 'plotly' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpsXLeZE\\downloaded_packages\npackage 'DT' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpsXLeZE\\downloaded_packages\n\nlibrary(ggiraph)\n\n\n\n\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\nlibrary(ggiraph)\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e.geom_dotplot_interactive()) will be used to create the basic graph. Then,girafe() will be used to generate an svg object to be displayed on an html page.\n\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#learning-outcome",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "First, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(plotly,patchwork, DT, tidyverse) \n\npackage 'lazyeval' successfully unpacked and MD5 sums checked\npackage 'crosstalk' successfully unpacked and MD5 sums checked\npackage 'plotly' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpsXLeZE\\downloaded_packages\npackage 'DT' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpsXLeZE\\downloaded_packages\n\nlibrary(ggiraph)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-packages",
    "title": "Take-home Exercise 1",
    "section": "Loading Packages",
    "text": "Loading Packages\n\n\n\nLibrary\nDescription\n\n\n\n\npacman\nPacman is a package that makes it possible to perform tasks associated with add-on packages in a more convenient manner. It checks whether the add-on packages are installed or not. If not, it will automatically install and load them into the R environment. In this take-home exercise 1, the pacman package has been installed beforehand.\n\n\ntidyverse\nA collection of core packages designed for data science, used extensively for data preparation and wrangling. Content includes: ggplot2, dplyr, tidyr, readr, purr, tibble, stringr, forcats, scales, lubridate, etc.\n\n\nscales\nThis package is designed to enhance how data is presented in visualisation, particularly in ggplot2 plots. It provides tools for mapping data to aesthetic attributes like colours, shapes, and sizes more effectively. It also includes functions for formatting and transforming axes and legends in a chart. Even though this is part of the tidyverse package collection, it needs to be installed and loaded separately.\n\n\nlubridate\nIt is a package to work with date-times and time-spans: fast and user-friendly parsing of date-time data, extraction and updating of components of a date-time (years, months, days, hours, minutes, and seconds), algebraic manipulation on date-time and time-span objects. This is part of the tidyverse collection, but it is not automatically loaded, so I will need to load it explicitly as I plan to use its functionality.\n\n\nggrepel\nAn R package provides geoms for ggplot2 to repel overlapping text labels. This is not part of the tidyverse package collection, but it is an extension of ggplot2.\n\n\nggthemes\nAnother separate R package that provides additional themes and scales for ggplot2 to enhance the appearance of plots. This package will also need to be installed and loaded independently.\n\n\nhrbrthemes\nThis package provides additional typography-centric themes and theme components for ggplot2, focused on improving readability and appearance for data visualisation. It must be installed and loaded independently.\n\n\npatchwork\nThis one is also an extension package for ggplot2 that allows combining multiple ggplot2 plots into one (composite figure) and arranging them in various layouts. Even though patchwork complements the functionality of ggplot2, it is independently maintained and must be installed and loaded separately.\n\n\n\nThe following code chunk utilises the p_load() function from the pacman package to ensure that the necessary packages are available in the R environment. If the packages are already installed on the computer, p_load() will load them. If they are not installed, it will first install them and then load them into the R environment.\n\npacman::p_load(tidyverse, scales,\n               lubridate, ggrepel, \n               ggthemes, hrbrthemes, \n               patchwork, knitr)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-the-data",
    "title": "Take-home Exercise 1",
    "section": "Loading The Data",
    "text": "Loading The Data\n\nThe Datasets\nThere are five datasets that cover from the start of the 1st quarter 2023 to the end of the 1st quarter 2024, I decided to load each dataset in a separate code chunk for better clarity in understanding the data types.\n\n\nQuarter 1, Year 2023:\n\nq1_2023 &lt;- read_csv(\"data/ResidentialTransaction20240308160536.csv\")\n\nRows: 4722 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Project Name, Sale Date, Address, Type of Sale, Type of Area, Nett...\ndbl  (1): Number of Units\nnum  (5): Transacted Price ($), Area (SQFT), Unit Price ($ PSF), Area (SQM),...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nQuarter 2, Year 2023:\n\nq2_2023 &lt;- read_csv(\"data/ResidentialTransaction20240308160736.csv\")\n\nRows: 6125 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Project Name, Sale Date, Address, Type of Sale, Type of Area, Nett...\ndbl  (1): Number of Units\nnum  (5): Transacted Price ($), Area (SQFT), Unit Price ($ PSF), Area (SQM),...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nQuarter 3, Year 2023:\n\nq3_2023 &lt;- read_csv(\"data/ResidentialTransaction20240308161009.csv\")\n\nRows: 6206 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Project Name, Sale Date, Address, Type of Sale, Type of Area, Nett...\ndbl  (2): Area (SQM), Number of Units\nnum  (4): Transacted Price ($), Area (SQFT), Unit Price ($ PSF), Unit Price ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs can be seen above, I noticed that in this particular dataset (Quarter 3, Year 2023), the data type for column Area (SQM) is ‘dbl’ (double), while in all the other four datasets, the data type for column Area (SQM) is ‘num’ (numeric). As far as I know, R does not differentiate between ‘dbl’ and ‘num’, so in this case, I will leave it as ‘dbl’ data type.\n\n\n\n\nQuarter 4, Year 2023:\n\nq4_2023 &lt;- read_csv(\"data/ResidentialTransaction20240308161109.csv\")\n\nRows: 4851 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Project Name, Sale Date, Address, Type of Sale, Type of Area, Nett...\ndbl  (1): Number of Units\nnum  (5): Transacted Price ($), Area (SQFT), Unit Price ($ PSF), Area (SQM),...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nQuarter 1, Year 2024:\n\nq1_2024 &lt;- read_csv(\"data/ResidentialTransaction20240414220633.csv\")\n\nRows: 4902 Columns: 21\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (15): Project Name, Sale Date, Address, Type of Sale, Type of Area, Nett...\ndbl  (1): Number of Units\nnum  (5): Transacted Price ($), Area (SQFT), Unit Price ($ PSF), Area (SQM),...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\nNote\n\n\n\nI also noticed that the Sale Date data type format in all of these five datasets is ‘chr’ (character). I will parse/convert them into date-time format."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#parsing-data-type",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#parsing-data-type",
    "title": "Take-home Exercise 1",
    "section": "Parsing Data Type",
    "text": "Parsing Data Type\nParsing the Sale Date column into date-time format using ‘lubridate’ package\n\nq1_2023 &lt;- q1_2023 %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`))\n\nq2_2023 &lt;- q2_2023 %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`))\n\nq3_2023 &lt;- q3_2023 %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`))\n\nq4_2023 &lt;- q4_2023 %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`))\n\nq1_2024 &lt;- q1_2024 %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`))\n\nExplanation:\n\nThe mutate() function is used to modify the Sale Date column directly.\n\nSince the column name has a space in it, I need to use backticks to refer to it within the mutate() function.\n\nThe dmy() function from the ‘lubridate’ package will parse the date strings into actual Date objects.\n\nNext, using the code below, I will check and confirm that the data types have been converted properly.\n\nclass(q1_2023$`Sale Date`)\n\n[1] \"Date\"\n\nclass(q2_2023$`Sale Date`)\n\n[1] \"Date\"\n\nclass(q3_2023$`Sale Date`)\n\n[1] \"Date\"\n\nclass(q4_2023$`Sale Date`)\n\n[1] \"Date\"\n\nclass(q1_2024$`Sale Date`)\n\n[1] \"Date\""
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#merge-the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#merge-the-data",
    "title": "Take-home Exercise 1",
    "section": "Merge the Data",
    "text": "Merge the Data\nAfter standardising the data in all five datasets, I will then merge these datasets together using the bind_rows() function from the ‘dplyr’ package. This function stacks data frames on top of each other, combining them into a single data frame. It’s important that all data frames have the same columns for bind_rows() to work correctly.\n\ncombined_data &lt;- bind_rows(q1_2023, q2_2023, q3_2023, q4_2023, q1_2024)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#inspect-the-merged-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#inspect-the-merged-data",
    "title": "Take-home Exercise 1",
    "section": "Inspect the Merged Data",
    "text": "Inspect the Merged Data\nAfter merging, it’s good practice to check the combined dataset to ensure everything looks as expected:\n\n# Check the structure of the combined data\nstr(combined_data)\n\ntibble [26,806 × 21] (S3: tbl_df/tbl/data.frame)\n $ Project Name               : chr [1:26806] \"THE REEF AT KING'S DOCK\" \"URBAN TREASURES\" \"NORTH GAIA\" \"NORTH GAIA\" ...\n $ Transacted Price ($)       : num [1:26806] 2317000 1823500 1421112 1258112 1280000 ...\n $ Area (SQFT)                : num [1:26806] 883 883 1076 1033 872 ...\n $ Unit Price ($ PSF)         : num [1:26806] 2625 2066 1320 1218 1468 ...\n $ Sale Date                  : Date[1:26806], format: \"2023-01-01\" \"2023-01-02\" ...\n $ Address                    : chr [1:26806] \"12 HARBOURFRONT AVENUE #05-32\" \"205 JALAN EUNOS #08-02\" \"29 YISHUN CLOSE #08-10\" \"45 YISHUN CLOSE #07-42\" ...\n $ Type of Sale               : chr [1:26806] \"New Sale\" \"New Sale\" \"New Sale\" \"New Sale\" ...\n $ Type of Area               : chr [1:26806] \"Strata\" \"Strata\" \"Strata\" \"Strata\" ...\n $ Area (SQM)                 : num [1:26806] 82 82 100 96 81 ...\n $ Unit Price ($ PSM)         : num [1:26806] 28256 22238 14211 13105 15802 ...\n $ Nett Price($)              : chr [1:26806] \"-\" \"-\" \"-\" \"-\" ...\n $ Property Type              : chr [1:26806] \"Condominium\" \"Condominium\" \"Executive Condominium\" \"Executive Condominium\" ...\n $ Number of Units            : num [1:26806] 1 1 1 1 1 1 1 1 1 1 ...\n $ Tenure                     : chr [1:26806] \"99 yrs from 12/01/2021\" \"Freehold\" \"99 yrs from 15/02/2021\" \"99 yrs from 15/02/2021\" ...\n $ Completion Date            : chr [1:26806] \"Uncompleted\" \"Uncompleted\" \"Uncompleted\" \"Uncompleted\" ...\n $ Purchaser Address Indicator: chr [1:26806] \"HDB\" \"Private\" \"HDB\" \"HDB\" ...\n $ Postal Code                : chr [1:26806] \"097996\" \"419535\" \"269343\" \"269294\" ...\n $ Postal District            : chr [1:26806] \"04\" \"14\" \"27\" \"27\" ...\n $ Postal Sector              : chr [1:26806] \"09\" \"41\" \"26\" \"26\" ...\n $ Planning Region            : chr [1:26806] \"Central Region\" \"East Region\" \"North Region\" \"North Region\" ...\n $ Planning Area              : chr [1:26806] \"Bukit Merah\" \"Bedok\" \"Yishun\" \"Yishun\" ...\n\n# View the first few rows to confirm data looks correct\nhead(combined_data)\n\n# A tibble: 6 × 21\n  `Project Name`       `Transacted Price ($)` `Area (SQFT)` `Unit Price ($ PSF)`\n  &lt;chr&gt;                                 &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt;\n1 THE REEF AT KING'S …                2317000          883.                 2625\n2 URBAN TREASURES                     1823500          883.                 2066\n3 NORTH GAIA                          1421112         1076.                 1320\n4 NORTH GAIA                          1258112         1033.                 1218\n5 PARC BOTANNIA                       1280000          872.                 1468\n6 NANYANG PARK                        5870000         3323.                 1767\n# ℹ 17 more variables: `Sale Date` &lt;date&gt;, Address &lt;chr&gt;, `Type of Sale` &lt;chr&gt;,\n#   `Type of Area` &lt;chr&gt;, `Area (SQM)` &lt;dbl&gt;, `Unit Price ($ PSM)` &lt;dbl&gt;,\n#   `Nett Price($)` &lt;chr&gt;, `Property Type` &lt;chr&gt;, `Number of Units` &lt;dbl&gt;,\n#   Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal Code` &lt;chr&gt;, `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n# Check for any missing values or anomalies\nsummary(combined_data)\n\n Project Name       Transacted Price ($)  Area (SQFT)       Unit Price ($ PSF)\n Length:26806       Min.   :   440000    Min.   :   322.9   Min.   : 138      \n Class :character   1st Qu.:  1280000    1st Qu.:   721.2   1st Qu.:1384      \n Mode  :character   Median :  1660000    Median :   990.3   Median :1762      \n                    Mean   :  2143286    Mean   :  1191.6   Mean   :1852      \n                    3rd Qu.:  2320000    3rd Qu.:  1302.4   3rd Qu.:2260      \n                    Max.   :392180000    Max.   :144883.4   Max.   :5756      \n                                                                              \n   Sale Date            Address          Type of Sale       Type of Area      \n Min.   :2023-01-01   Length:26806       Length:26806       Length:26806      \n 1st Qu.:2023-04-29   Class :character   Class :character   Class :character  \n Median :2023-07-28   Mode  :character   Mode  :character   Mode  :character  \n Mean   :2023-08-11                                                           \n 3rd Qu.:2023-11-20                                                           \n Max.   :2024-03-31                                                           \n                                                                              \n   Area (SQM)      Unit Price ($ PSM) Nett Price($)      Property Type     \n Min.   :   30.0   Min.   : 1484      Length:26806       Length:26806      \n 1st Qu.:   67.0   1st Qu.:14893      Class :character   Class :character  \n Median :   92.0   Median :18966      Mode  :character   Mode  :character  \n Mean   :  110.5   Mean   :19930                                           \n 3rd Qu.:  121.0   3rd Qu.:24327                                           \n Max.   :13460.0   Max.   :61962                                           \n NA's   :6                                                                 \n Number of Units     Tenure          Completion Date   \n Min.   : 1.000   Length:26806       Length:26806      \n 1st Qu.: 1.000   Class :character   Class :character  \n Median : 1.000   Mode  :character   Mode  :character  \n Mean   : 1.005                                        \n 3rd Qu.: 1.000                                        \n Max.   :60.000                                        \n                                                       \n Purchaser Address Indicator Postal Code        Postal District   \n Length:26806                Length:26806       Length:26806      \n Class :character            Class :character   Class :character  \n Mode  :character            Mode  :character   Mode  :character  \n                                                                  \n                                                                  \n                                                                  \n                                                                  \n Postal Sector      Planning Region    Planning Area     \n Length:26806       Length:26806       Length:26806      \n Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#save-the-merged-dataset",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#save-the-merged-dataset",
    "title": "Take-home Exercise 1",
    "section": "Save the Merged Dataset",
    "text": "Save the Merged Dataset\nSince I may need to use to use this merged datasets repeatedly, I will save it into a file for easy access in future sessions. I will use write_csv() function from the ‘readr’ package (part of the ‘tidyverse’) to write this merged data frame to a CSV file.\n\nwrite_csv(combined_data, \"data/All_ResidentialTransactions_2023-2024.csv\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#step-8-proceed-with-visualisation-and-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#step-8-proceed-with-visualisation-and-analysis",
    "title": "Take-home Exercise 1",
    "section": "Step 8: Proceed with Visualisation and Analysis",
    "text": "Step 8: Proceed with Visualisation and Analysis\nNow the data has been consolidated into a single dataframe, it is time to move forward with analysis:\n\nDescriptive Statistics: Summarize the data to get a sense of trends or patterns.\nTime Series Analysis: Analyze changes over time across different quarters.\nVisualizations: Create plots to visualize trends, distributions, and relationships in the data.\n\nAfter all the previous setup and loaded libraries, next is to create the visualization to see the trends in the data.\n\n# Generate a Month-Year field for the x-axis and calculate total sales volume\nmonthly_sales_stats &lt;- combined_data %&gt;%\n  mutate(Month = floor_date(`Sale Date`, unit = \"month\")) %&gt;%\n  group_by(Month) %&gt;%\n  summarise(Total_Sales_Volume = sum(`Number of Units`, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  arrange(Month)\n\n# Calculate the average monthly sales volume\naverage_sales_volume &lt;- mean(monthly_sales_stats$Total_Sales_Volume)\n\n# Create the line chart visualizing monthly sales volume and add the average reference line\nmonthly_sales_line_chart &lt;- ggplot(monthly_sales_stats, aes(x = Month, y = Total_Sales_Volume)) +\n  geom_line(color = \"black\") +  # Line color\n  geom_point(color = \"black\") +  # Point color\n  geom_hline(yintercept = average_sales_volume, linetype = \"dotted\", color = \"red\", size = 1) +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n  theme_minimal() +\n  labs(\n    title = \"Monthly Sales Volume with Average Reference Line\",\n    x = \"Month\",\n    y = \"Total Units Sold\"\n  ) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))  # Rotate the x-axis text for better readability\n\n# Print the plot\nmonthly_sales_line_chart\n\n\n\n\nThe visualisation illustrates the monthly sales volume trend of private housing units from January 2023 to March 2024. The trend shows significant fluctuation throughout the period, with peaks and troughs corresponding to market activity. Notably, there’s a sharp increase in March 2023, suggesting a spike in sales, possibly due to market stimuli or seasonal factors. The overall pattern indicates a resilient market, yet with periods of reticence, potentially reflective of economic events or policy changes. The red dotted line represents the average sales volume across the period, providing a benchmark against which to compare monthly performance. The months above this line saw higher-than-average sales, whereas those below saw fewer transactions, highlighting the varying buyer activity throughout the year.\n\n# First, we aggregate the number of units sold by property type\nproperty_type_distribution &lt;- combined_data %&gt;%\n  group_by(`Property Type`) %&gt;%\n  summarise(Transactions = n(), .groups = 'drop')\n\n# Now, we plot the distribution\nproperty_type_chart &lt;- ggplot(property_type_distribution, aes(x = `Property Type`, y = Transactions)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") + # All bars in 'steelblue'\n  theme_minimal() +\n  labs(title = \"Sales Distribution based on Property Type in Singapore Private Residential Market\",\n       x = \"Property Type\",\n       y = \"Number of Transactions\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1),\n        legend.position = \"none\") # Remove legend\n\n# Print the plot\nprint(property_type_chart)\n\n\n\n\nThe bar chart illustrates the frequency of transactions across different property types in Singapore’s private residential market. Condominiums and apartments are the most commonly traded, suggesting a high demand for such property types, which could be due to their affordability and availability. Executive condominiums and detached houses represent a smaller fraction, likely reflecting their higher price points and more exclusive market position. The varied transaction volume across property types offers valuable insight into consumer preferences and the real estate market’s dynamics, particularly indicating a trend towards high-density living options.\n\n# Filter for Apartments and Condominiums only\napt_condo_data &lt;- combined_data %&gt;%\n  filter(`Property Type` %in% c(\"Apartment\", \"Condominium\"))\n\n# Create the box plots\nprice_comparison_plot &lt;- ggplot(apt_condo_data, aes(x = `Property Type`, y = `Transacted Price ($)`, color = `Property Type`)) +\n  geom_boxplot() +\n  scale_color_manual(values = c(\"blue\", \"green\")) + # You can choose your own colors\n  theme_minimal() +\n  labs(title = \"Price Distribution for Apartments and Condominiums\",\n       x = \"Property Type\",\n       y = \"Transacted Price ($)\") +\n  theme(legend.position = \"none\") # This removes the legend\n\n# Print the plot\nprint(price_comparison_plot)\n\n\n\n\n\n# Filter combined_data for condominiums\ncondo_sales &lt;- combined_data %&gt;% \n  filter(`Property Type` == \"Condominium\")\n\n# Create a histogram to display the price distribution for condos\nggplot(condo_sales, aes(x = `Transacted Price ($)`)) +\n  geom_histogram(bins = 30, fill = \"blue\", color = \"black\") + # Adjust the number of bins as necessary\n  theme_minimal() +\n  labs(title = \"Price Distribution of Condominiums\",\n       x = \"Sale Price ($)\",\n       y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for readability\n\n\n\n\n\n# Assuming your combined_data dataframe has 'Transacted Price ($)' for the sale prices\n# and 'Property Type' for filtering to \"Condominium\"\n\n# Filter combined_data for condominiums\ncondo_sales &lt;- combined_data %&gt;% \n  filter(`Property Type` == \"Condominium\")\n\n# Create a density plot to display the price distribution for condos\nggplot(condo_sales, aes(x = `Transacted Price ($)`)) +\n  geom_density(fill = \"blue\", alpha = 0.5) + # Adjust the color and transparency as needed\n  theme_minimal() +\n  labs(title = \"Price Distribution of Condominiums - Density Plot\",\n       x = \"Sale Price ($)\",\n       y = \"Density\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels for readability"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#proceed-with-visualisation-and-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#proceed-with-visualisation-and-analysis",
    "title": "Take-home Exercise 1",
    "section": "Proceed with Visualisation and Analysis",
    "text": "Proceed with Visualisation and Analysis\nNow that the data has been consolidated into a single dataframe, it is time to move forward with analysis:\nAfter completing all the previous setup and loading libraries, the next step is to create the visualisations to gather insights from the data.\n\nMonthly Sales Volume Visualisation with Average Reference Line\n\n# Generate a Month-Year field for the x-axis and calculate total sales volume\nmonthly_sales_stats &lt;- combined_data %&gt;%\n  mutate(Month = floor_date(`Sale Date`, unit = \"month\")) %&gt;%\n  group_by(Month) %&gt;%\n  summarise(Total_Sales_Volume = sum(`Number of Units`, na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  arrange(Month)\n\n# Calculate the average monthly sales volume\naverage_sales_volume &lt;- mean(monthly_sales_stats$Total_Sales_Volume)\n\n# Create the line chart visualizing monthly sales volume and add the average reference line\nmonthly_sales_line_chart &lt;- ggplot(monthly_sales_stats, aes(x = Month, y = Total_Sales_Volume)) +\n  geom_line(color = \"black\") +  # Line color\n  geom_point(color = \"black\") +  # Point color\n  geom_hline(yintercept = average_sales_volume, linetype = \"dotted\", color = \"red\", size = 1) +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b %Y\") +\n  theme_minimal() +\n  labs(\n    title = \"Monthly Sales Volume with Average Reference Line\",\n    x = \"Month\",\n    y = \"Total Units Sold\"\n  ) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))  # Rotate the x-axis text for better readability\n\n# Print the plot\nmonthly_sales_line_chart\n\n\n\n\n\n\n\n\nThe visualisation illustrates the monthly sales volume trend for private housing units from January 2023 to March 2024. The trend exhibits significant fluctuations throughout the period, with peaks and troughs corresponding to market activities. Notably, there is a sharp increase in March 2024 as compared to February 2024, suggesting a spike in sales. Huttons Asia’s chief executive, Mark Yip, attributes this to the resumption of project launches in March following the Chinese New Year festive lull, which had a spillover effect on the resale market (Yip, 2024). The red dotted line represents the average sales volume over the period, providing a benchmark for monthly performance comparison. Months above this line experienced higher-than-average sales, while those below indicated fewer transactions, highlighting the variable buyer activity throughout the year.\nCitation: Yip, M. (2024, April 26). Condo resale prices inch up in March as volume rebounds 17.4%. The Straits Times. Retrieved from [https://www.straitstimes.com/singapore/housing/condo-resale-prices-inch-up-in-march-as-volume-rebounds-174]\n\n\nSales Distribution based on Property type in Singapore Private Residential Market\n\n# First, we aggregate the number of units sold by property type\nproperty_type_distribution &lt;- combined_data %&gt;%\n  group_by(`Property Type`) %&gt;%\n  summarise(Transactions = n(), .groups = 'drop')\n\n# Now, we plot the distribution\nproperty_type_chart &lt;- ggplot(property_type_distribution, aes(x = Transactions, y = reorder(`Property Type`, Transactions))) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\", orientation = \"y\") + # All bars in 'steelblue'\n  theme_minimal() +\n  labs(title = \"Sales Distribution based on Property Type\",\n       x = \"Number of Transactions\",\n       y = \"Property Type\") +\n  theme(axis.text.x = element_text(angle = 0, hjust = 1),\n        legend.position = \"none\") # Remove legend\n\n# Print the plot\nprint(property_type_chart)\n\n\n\n\n\n\n\n\nThe bar chart illustrates the frequency of transactions across different property types in Singapore’s private residential market. Condominiums and apartments are the most commonly traded, suggesting a high demand for such property types, which could be due to their affordability and availability. Executive condominiums and detached houses represent a smaller fraction, likely reflecting their higher price points and more exclusive market position. The varied transaction volume across property types offers valuable insight into consumer preferences and the real estate market’s dynamics, particularly indicating a trend towards high-density living options."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#loading-r-packages",
    "title": "In-class Exercise 3",
    "section": "Loading R packages",
    "text": "Loading R packages\n\npacman::p_load(tidyverse, ggdist, ggridges,\n               colorspace, ggthemes)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-distribution",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-distribution",
    "title": "In-class Exercise 3",
    "section": "Visualising Distribution",
    "text": "Visualising Distribution"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#histogram",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#histogram",
    "title": "In-class Exercise 3",
    "section": "Histogram",
    "text": "Histogram"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-distribution-1",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-distribution-1",
    "title": "In-class Exercise 3",
    "section": "Visualising Distribution",
    "text": "Visualising Distribution"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#probability-density-plot",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#probability-density-plot",
    "title": "In-class Exercise 3",
    "section": "Probability density plot",
    "text": "Probability density plot\n\nThe taskThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam_df,\n       aes(x = ENGLISH)) +\n  geom_density(\n    color = \"#1696d2\",\n    adjust = .65,\n    alpha = .6\n  )\n\n\n\n\nmedian_eng &lt;- median(exam_df\\(ENGLISH) mean_eng &lt;- mean(exam_df\\)ENGLISH) std_eng &lt;_ sd(exam_df$ENGLISH)\nggplot(exam_df, aes(x = ENGLISH)) geom_density( color = “#1696d2”, adjust = .65, alpha = .6) + stat_function( fun = dnorm, args = list(mean = mean_eng, sd = std_eng), col = “grey30”, size = 0.8) + geom_vline( aes(xintercept = mean_eng), colour=“4d5887”, linewidth = 0.6, linetype = “dashed”) + annotate(geom = “text”, x = mean_eng - 8 y = 0.04, label = paste0(“Mean ENGLISH:”, round((mean_eng), 2)), ) ) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\nggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nOnce again, Exam_data.csv will be utilized for the exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-outcome",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#getting-started",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nOnce again, Exam_data.csv will be utilized for the exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "ggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\nlibrary(ggiraph)\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e.geom_dotplot_interactive()) will be used to create the basic graph. Then,girafe() will be used to generate an svg object to be displayed on an html page."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#interactivity",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "By hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#interactivity-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#interactivity-1",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "By hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "ggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html",
    "title": "Hands-on Exercise 4A",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\nggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\npackage 'pkgbuild' successfully unpacked and MD5 sums checked\npackage 'rprojroot' successfully unpacked and MD5 sums checked\npackage 'diffobj' successfully unpacked and MD5 sums checked\npackage 'brio' successfully unpacked and MD5 sums checked\npackage 'desc' successfully unpacked and MD5 sums checked\npackage 'pkgload' successfully unpacked and MD5 sums checked\npackage 'praise' successfully unpacked and MD5 sums checked\npackage 'waldo' successfully unpacked and MD5 sums checked\npackage 'testthat' successfully unpacked and MD5 sums checked\npackage 'SparseM' successfully unpacked and MD5 sums checked\npackage 'minqa' successfully unpacked and MD5 sums checked\npackage 'nloptr' successfully unpacked and MD5 sums checked\npackage 'carData' successfully unpacked and MD5 sums checked\npackage 'abind' successfully unpacked and MD5 sums checked\npackage 'quantreg' successfully unpacked and MD5 sums checked\npackage 'elliptic' successfully unpacked and MD5 sums checked\npackage 'contfrac' successfully unpacked and MD5 sums checked\npackage 'deSolve' successfully unpacked and MD5 sums checked\npackage 'plyr' successfully unpacked and MD5 sums checked\npackage 'lme4' successfully unpacked and MD5 sums checked\npackage 'pbkrtest' successfully unpacked and MD5 sums checked\npackage 'lmerTest' successfully unpacked and MD5 sums checked\npackage 'car' successfully unpacked and MD5 sums checked\npackage 'coda' successfully unpacked and MD5 sums checked\npackage 'pbapply' successfully unpacked and MD5 sums checked\npackage 'mvtnorm' successfully unpacked and MD5 sums checked\npackage 'MatrixModels' successfully unpacked and MD5 sums checked\npackage 'hypergeo' successfully unpacked and MD5 sums checked\npackage 'RcppEigen' successfully unpacked and MD5 sums checked\npackage 'multcompView' successfully unpacked and MD5 sums checked\npackage 'gmp' successfully unpacked and MD5 sums checked\npackage 'Rmpfr' successfully unpacked and MD5 sums checked\npackage 'SuppDists' successfully unpacked and MD5 sums checked\npackage 'kSamples' successfully unpacked and MD5 sums checked\npackage 'BWStest' successfully unpacked and MD5 sums checked\npackage 'reshape' successfully unpacked and MD5 sums checked\npackage 'bayestestR' successfully unpacked and MD5 sums checked\npackage 'reshape2' successfully unpacked and MD5 sums checked\npackage 'prismatic' successfully unpacked and MD5 sums checked\npackage 'afex' successfully unpacked and MD5 sums checked\npackage 'BayesFactor' successfully unpacked and MD5 sums checked\npackage 'effectsize' successfully unpacked and MD5 sums checked\npackage 'PMCMRplus' successfully unpacked and MD5 sums checked\npackage 'WRS2' successfully unpacked and MD5 sums checked\npackage 'zeallot' successfully unpacked and MD5 sums checked\npackage 'correlation' successfully unpacked and MD5 sums checked\npackage 'datawizard' successfully unpacked and MD5 sums checked\npackage 'ggcorrplot' successfully unpacked and MD5 sums checked\npackage 'ggside' successfully unpacked and MD5 sums checked\npackage 'ggsignif' successfully unpacked and MD5 sums checked\npackage 'insight' successfully unpacked and MD5 sums checked\npackage 'paletteer' successfully unpacked and MD5 sums checked\npackage 'parameters' successfully unpacked and MD5 sums checked\npackage 'performance' successfully unpacked and MD5 sums checked\npackage 'statsExpressions' successfully unpacked and MD5 sums checked\npackage 'ggstatsplot' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\Rtmp8MdDUQ\\downloaded_packages\n\n\n\n\n\nOnce again, Exam_data.csv will be utilized for the exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo-It-Yourself\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\npackage 'modelbased' successfully unpacked and MD5 sums checked\npackage 'see' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\Rtmp8MdDUQ\\downloaded_packages\n\n\n\n\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk, check_normality() of performance package.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\n\n\n\n\n\n\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#learning-outcome",
    "title": "Hands-on Exercise 4A",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4A",
    "section": "",
    "text": "ggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#getting-started",
    "title": "Hands-on Exercise 4A",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\npackage 'pkgbuild' successfully unpacked and MD5 sums checked\npackage 'rprojroot' successfully unpacked and MD5 sums checked\npackage 'diffobj' successfully unpacked and MD5 sums checked\npackage 'brio' successfully unpacked and MD5 sums checked\npackage 'desc' successfully unpacked and MD5 sums checked\npackage 'pkgload' successfully unpacked and MD5 sums checked\npackage 'praise' successfully unpacked and MD5 sums checked\npackage 'waldo' successfully unpacked and MD5 sums checked\npackage 'testthat' successfully unpacked and MD5 sums checked\npackage 'SparseM' successfully unpacked and MD5 sums checked\npackage 'minqa' successfully unpacked and MD5 sums checked\npackage 'nloptr' successfully unpacked and MD5 sums checked\npackage 'carData' successfully unpacked and MD5 sums checked\npackage 'abind' successfully unpacked and MD5 sums checked\npackage 'quantreg' successfully unpacked and MD5 sums checked\npackage 'elliptic' successfully unpacked and MD5 sums checked\npackage 'contfrac' successfully unpacked and MD5 sums checked\npackage 'deSolve' successfully unpacked and MD5 sums checked\npackage 'plyr' successfully unpacked and MD5 sums checked\npackage 'lme4' successfully unpacked and MD5 sums checked\npackage 'pbkrtest' successfully unpacked and MD5 sums checked\npackage 'lmerTest' successfully unpacked and MD5 sums checked\npackage 'car' successfully unpacked and MD5 sums checked\npackage 'coda' successfully unpacked and MD5 sums checked\npackage 'pbapply' successfully unpacked and MD5 sums checked\npackage 'mvtnorm' successfully unpacked and MD5 sums checked\npackage 'MatrixModels' successfully unpacked and MD5 sums checked\npackage 'hypergeo' successfully unpacked and MD5 sums checked\npackage 'RcppEigen' successfully unpacked and MD5 sums checked\npackage 'multcompView' successfully unpacked and MD5 sums checked\npackage 'gmp' successfully unpacked and MD5 sums checked\npackage 'Rmpfr' successfully unpacked and MD5 sums checked\npackage 'SuppDists' successfully unpacked and MD5 sums checked\npackage 'kSamples' successfully unpacked and MD5 sums checked\npackage 'BWStest' successfully unpacked and MD5 sums checked\npackage 'reshape' successfully unpacked and MD5 sums checked\npackage 'bayestestR' successfully unpacked and MD5 sums checked\npackage 'reshape2' successfully unpacked and MD5 sums checked\npackage 'prismatic' successfully unpacked and MD5 sums checked\npackage 'afex' successfully unpacked and MD5 sums checked\npackage 'BayesFactor' successfully unpacked and MD5 sums checked\npackage 'effectsize' successfully unpacked and MD5 sums checked\npackage 'PMCMRplus' successfully unpacked and MD5 sums checked\npackage 'WRS2' successfully unpacked and MD5 sums checked\npackage 'zeallot' successfully unpacked and MD5 sums checked\npackage 'correlation' successfully unpacked and MD5 sums checked\npackage 'datawizard' successfully unpacked and MD5 sums checked\npackage 'ggcorrplot' successfully unpacked and MD5 sums checked\npackage 'ggside' successfully unpacked and MD5 sums checked\npackage 'ggsignif' successfully unpacked and MD5 sums checked\npackage 'insight' successfully unpacked and MD5 sums checked\npackage 'paletteer' successfully unpacked and MD5 sums checked\npackage 'parameters' successfully unpacked and MD5 sums checked\npackage 'performance' successfully unpacked and MD5 sums checked\npackage 'statsExpressions' successfully unpacked and MD5 sums checked\npackage 'ggstatsplot' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\Rtmp8MdDUQ\\downloaded_packages\n\n\n\n\n\nOnce again, Exam_data.csv will be utilized for the exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html",
    "title": "Hands-on Exercise 4C",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages.\n\n\n\n\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\npackage 'FunnelPlotR' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpEd4rFh\\downloaded_packages\n\n\n\n\n\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\n\n\n\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.\n\n\n\n\n\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly\n\n\n\n\n\n\n\n\n\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#learning-outcome",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "ggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#getting-started",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nOnce again, Exam_data.csv will be utilized for the exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html",
    "title": "Hands-on Exercise 4B",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package.\n\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nstrapgod (NA -&gt; ea2b1ecfc...) [GitHub]\n\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file 'C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpCezAJG\\remotes75585cc16a3d\\DavisVaughan-strapgod-ea2b1ec/DESCRIPTION' ... OK\n* preparing 'strapgod':\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted 'LazyData' from DESCRIPTION\n* building 'strapgod_0.0.4.9000.tar.gz'\n\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file 'C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpCezAJG\\remotes755838015322\\wilkelab-ungeviz-aeae12b/DESCRIPTION' ... OK\n* preparing 'ungeviz':\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\n* building 'ungeviz_0.1.0.tar.gz'\n\n\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\npackage 'proxy' successfully unpacked and MD5 sums checked\npackage 'e1071' successfully unpacked and MD5 sums checked\npackage 'wk' successfully unpacked and MD5 sums checked\npackage 'classInt' successfully unpacked and MD5 sums checked\npackage 's2' successfully unpacked and MD5 sums checked\npackage 'units' successfully unpacked and MD5 sums checked\npackage 'sf' successfully unpacked and MD5 sums checked\npackage 'lpSolve' successfully unpacked and MD5 sums checked\npackage 'transformr' successfully unpacked and MD5 sums checked\npackage 'tweenr' successfully unpacked and MD5 sums checked\npackage 'gganimate' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpCezAJG\\downloaded_packages\n\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor the mathematical explanation, please refer to Slide 20 of Lesson 4.\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\n\n\n\n\n\n\n\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour turn\n\n\n\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\n\n\nStep 1: Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nNote: You only need to perform this step once.\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\nNULL\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)\n\nNULL"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#learning-outcome",
    "title": "Hands-on Exercise 4B",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "ggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#getting-started",
    "title": "Hands-on Exercise 4B",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nstrapgod (NA -&gt; ea2b1ecfc...) [GitHub]\n\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file 'C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpCezAJG\\remotes75585cc16a3d\\DavisVaughan-strapgod-ea2b1ec/DESCRIPTION' ... OK\n* preparing 'strapgod':\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted 'LazyData' from DESCRIPTION\n* building 'strapgod_0.0.4.9000.tar.gz'\n\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file 'C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpCezAJG\\remotes755838015322\\wilkelab-ungeviz-aeae12b/DESCRIPTION' ... OK\n* preparing 'ungeviz':\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\n* building 'ungeviz_0.1.0.tar.gz'\n\n\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\npackage 'proxy' successfully unpacked and MD5 sums checked\npackage 'e1071' successfully unpacked and MD5 sums checked\npackage 'wk' successfully unpacked and MD5 sums checked\npackage 'classInt' successfully unpacked and MD5 sums checked\npackage 's2' successfully unpacked and MD5 sums checked\npackage 'units' successfully unpacked and MD5 sums checked\npackage 'sf' successfully unpacked and MD5 sums checked\npackage 'lpSolve' successfully unpacked and MD5 sums checked\npackage 'transformr' successfully unpacked and MD5 sums checked\npackage 'tweenr' successfully unpacked and MD5 sums checked\npackage 'gganimate' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpCezAJG\\downloaded_packages\n\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#visualising-models",
    "title": "Hands-on Exercise 4A",
    "section": "",
    "text": "In this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04a.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4A",
    "section": "",
    "text": "Do-It-Yourself\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\npackage 'modelbased' successfully unpacked and MD5 sums checked\npackage 'see' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\Rtmp8MdDUQ\\downloaded_packages\n\n\n\n\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk, check_normality() of performance package.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\n\n\n\n\n\n\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html",
    "title": "Hands-on Exercise 4A",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\nggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nOnce again, Exam_data.csv will be utilized for the exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDo-It-Yourself\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#learning-outcome",
    "title": "Hands-on Exercise 4A",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4A",
    "section": "",
    "text": "ggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#getting-started",
    "title": "Hands-on Exercise 4A",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nOnce again, Exam_data.csv will be utilized for the exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#visualising-models",
    "title": "Hands-on Exercise 4A",
    "section": "",
    "text": "In this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#installing-and-loading-the-required-libraries",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04A.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4A",
    "section": "",
    "text": "Do-It-Yourself\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\nggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nOnce again, Exam_data.csv will be utilized for the exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#learning-outcome",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "ggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04C.html#getting-started",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nOnce again, Exam_data.csv will be utilized for the exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\nggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nOnce again, Exam_data.csv will be utilized for the exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html#learning-outcome",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "ggstatsplot  is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04B.html#getting-started",
    "title": "Hands-on Exercise 4",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\nOnce again, Exam_data.csv will be utilized for the exercise.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4B",
    "section": "",
    "text": "A point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor the mathematical explanation, please refer to Slide 20 of Lesson 4.\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4B",
    "section": "",
    "text": "ggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour turn\n\n\n\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 4B",
    "section": "",
    "text": "Step 1: Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nNote: You only need to perform this step once.\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\nNULL"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04b.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "title": "Hands-on Exercise 4B",
    "section": "",
    "text": "ggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)\n\nNULL"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#overview",
    "title": "Hands-on Exercise 4C",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4C",
    "section": "",
    "text": "In this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\npackage 'FunnelPlotR' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Arya Siahaan\\AppData\\Local\\Temp\\RtmpEd4rFh\\downloaded_packages"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#importing-data",
    "title": "Hands-on Exercise 4C",
    "section": "",
    "text": "In this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#funnelplotr-methods",
    "title": "Hands-on Exercise 4C",
    "section": "",
    "text": "FunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 7 are outliers.  Plot is adjusted for overdispersion. \nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4C",
    "section": "",
    "text": "In this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04c.html#references",
    "title": "Hands-on Exercise 4C",
    "section": "",
    "text": "funnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#loading-r-packages",
    "title": "In-class_Ex04",
    "section": "Loading R packages",
    "text": "Loading R packages\n\npacman::p_load(tidyverse, ggstatsplot)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "In this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "ggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\nlibrary(ggiraph)\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e.geom_dotplot_interactive()) will be used to create the basic graph. Then,girafe() will be used to generate an svg object to be displayed on an html page."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "By hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity-1",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "By hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "For Take-home Exercise 2, I need to choose a data visualisation prepared by one of my classmate’s Take-home Exercise 1 submission, critique its clarity and aesthetics, and then redesign it using the ggplot2 and tidyverse packages, including ggplot2 extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-task",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "For Take-home Exercise 2, I need to choose a data visualisation prepared by one of my classmate’s Take-home Exercise 1 submission, critique its clarity and aesthetics, and then redesign it using the ggplot2 and tidyverse packages, including ggplot2 extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#reproducing-the-original-process",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#reproducing-the-original-process",
    "title": "Take-home Exercise 2",
    "section": "Reproducing The Original Process",
    "text": "Reproducing The Original Process\nI will follow the step-by-step process performed by my classmate in order to reproduce the original visualisation.\n\nLoading The Packages\nFirst of all, let’s load all the required packages to reproduce the visualisation. The packages used are listed below:\n\n\n\nLibrary\nDescription\n\n\n\n\npacman\nPacman is a package that makes it possible to perform tasks associated with add-on packages in a more convenient manner. It checks whether the add-on packages are installed or not. If not, it will automatically install and load them into the R environment.\n\n\ntidyverse\nA collection of core packages designed for data science, used extensively for data preparation and wrangling. Content includes: ggplot2, dplyr, tidyr, readr, purr, tibble, stringr, forcats, scales, lubridate, etc.\n\n\npatchwork\nThis one is also an extension package for ggplot2 that allows combining multiple ggplot2 plots into one (composite figure) and arranging them in various layouts. Even though patchwork complements the functionality of ggplot2, it is independently maintained and must be installed and loaded separately.\n\n\nscales\nThis package is designed to enhance how data is presented in visualisation, particularly in ggplot2 plots. It provides tools for mapping data to aesthetic attributes like colours, shapes, and sizes more effectively. It also includes functions for formatting and transforming axes and legends in a chart. Even though this is part of the tidyverse package collection, it needs to be installed and loaded separately.\n\n\nzoo\nProvides powerful methods for managing and manipulating ordered indexed data, particularly time series data, making it easier to handle a variety of data irregularities.\n\n\n\nThese packages will be loaded using the p_load() function from the pacman package to ensure that all the necessary packages are available in the R environment.\n\npacman::p_load(tidyverse, lubridate, patchwork, scales, zoo)\n\n\n\nLoading The Data\n\nThe Datasets\nThere are five datasets in the form of CSV files used to produce the original visualisation. These datasets cover from the start of the 1st quarter 2023 to the end of the 1st quarter 2024.\n\nread_csv() function will be used to load these CSV files into the R environment to create five separate dataframes: data1, data2, data3, data4, and data5.\nbind_rows() from the dplyr package merges these five data frames into one large data frame called data.\nglimpse() provides a quick overview of the combined data frame.\n\n\ndata1 = read_csv(\"data/ResidentialTransaction20240308160536.csv\")\ndata2 = read_csv(\"data/ResidentialTransaction20240308160736.csv\")\ndata3 = read_csv(\"data/ResidentialTransaction20240308161009.csv\")\ndata4 = read_csv(\"data/ResidentialTransaction20240308161109.csv\")\ndata5 = read_csv(\"data/ResidentialTransaction20240414220633.csv\")\ndata &lt;- bind_rows(data1, data2, data3, data4, data5)\n\nglimpse(data)\n\nRows: 26,806\nColumns: 21\n$ `Project Name`                &lt;chr&gt; \"THE REEF AT KING'S DOCK\", \"URBAN TREASU…\n$ `Transacted Price ($)`        &lt;dbl&gt; 2317000, 1823500, 1421112, 1258112, 1280…\n$ `Area (SQFT)`                 &lt;dbl&gt; 882.65, 882.65, 1076.40, 1033.34, 871.88…\n$ `Unit Price ($ PSF)`          &lt;dbl&gt; 2625, 2066, 1320, 1218, 1468, 1767, 1095…\n$ `Sale Date`                   &lt;chr&gt; \"01 Jan 2023\", \"02 Jan 2023\", \"02 Jan 20…\n$ Address                       &lt;chr&gt; \"12 HARBOURFRONT AVENUE #05-32\", \"205 JA…\n$ `Type of Sale`                &lt;chr&gt; \"New Sale\", \"New Sale\", \"New Sale\", \"New…\n$ `Type of Area`                &lt;chr&gt; \"Strata\", \"Strata\", \"Strata\", \"Strata\", …\n$ `Area (SQM)`                  &lt;dbl&gt; 82.0, 82.0, 100.0, 96.0, 81.0, 308.7, 42…\n$ `Unit Price ($ PSM)`          &lt;dbl&gt; 28256, 22238, 14211, 13105, 15802, 19015…\n$ `Nett Price($)`               &lt;chr&gt; \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", …\n$ `Property Type`               &lt;chr&gt; \"Condominium\", \"Condominium\", \"Executive…\n$ `Number of Units`             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Tenure                        &lt;chr&gt; \"99 yrs from 12/01/2021\", \"Freehold\", \"9…\n$ `Completion Date`             &lt;chr&gt; \"Uncompleted\", \"Uncompleted\", \"Uncomplet…\n$ `Purchaser Address Indicator` &lt;chr&gt; \"HDB\", \"Private\", \"HDB\", \"HDB\", \"HDB\", \"…\n$ `Postal Code`                 &lt;chr&gt; \"097996\", \"419535\", \"269343\", \"269294\", …\n$ `Postal District`             &lt;chr&gt; \"04\", \"14\", \"27\", \"27\", \"28\", \"19\", \"10\"…\n$ `Postal Sector`               &lt;chr&gt; \"09\", \"41\", \"26\", \"26\", \"79\", \"54\", \"27\"…\n$ `Planning Region`             &lt;chr&gt; \"Central Region\", \"East Region\", \"North …\n$ `Planning Area`               &lt;chr&gt; \"Bukit Merah\", \"Bedok\", \"Yishun\", \"Yishu…\n\n\n\n\n\nVariable Selection\n\n\n\n\n\n\n\nCategory\nDescription\n\n\n\n\nProject Name\nthe name of the property or title of the development project that is being sold\n\n\nSale Date\nThe specific date when the transaction was completed\n\n\nType of Sale\nA new sale, resale, or auction, among other types.Here mainly analyze resale\n\n\nArea (SQM)\nThe usable floor area of the property in square meters\n\n\nUnit Price ($ PSM)\nThe price per square meter of the property\n\n\n\n\nData Cleaning\nSale Date is converted to a date format using the dmy() function from the lubridate package, which interprets strings as dates in “day-month-year” format.\nArea (SQM) is transformed into a numeric variable.\nUnit Price ($ PSM) undergoes a similar process as Area (SQM).\nAny NA (missing) values in Area (SQM) is replaced with 0\nA new variable Area_Category is created using the cut() function to categorize the Area (SQM). variable into predefined bins: &lt;100, 100-200, 200-300, 300-400, &gt;400.\nThe breaks argument specifies the boundaries for these bins, and labels provides the corresponding category labels.\ninclude.lowest = TRUE ensures that values equal to the lowest break point (0) are included in the first category (&lt;100).\n\ndata_cleaned &lt;- data %&gt;%\n  mutate(\n    `Sale Date` = dmy(`Sale Date`),  # Ensuring we're using the exact column name from the dataset\n    `Area (SQM)` = as.numeric(gsub(\",\", \"\", `Area (SQM)`)),  # Keeping the variable names as they are in the dataset\n    `Unit Price ($ PSM)` = as.numeric(gsub(\"\\\\$\", \"\", gsub(\",\", \"\", `Unit Price ($ PSM)`)))  # Properly referencing the variable\n  )\n\ndata_cleaned &lt;- data_cleaned %&gt;%\n  mutate(\n    `Area (SQM)` = ifelse(is.na(`Area (SQM)`), 0, `Area (SQM)`)  # Dealing with NA values\n  )\n\ndata_cleaned &lt;- data_cleaned %&gt;%\n  mutate(\n    Area_Category = cut(\n      `Area (SQM)`,\n      breaks = c(0, 100, 200, 300, 400, Inf),  \n      labels = c(\"&lt;100\", \"100-200\", \"200-300\", \"300-400\", \"&gt;400\"),\n      include.lowest = TRUE  \n    )\n  )\n\n\n\nReproducing The Original Visualization\nThe plot below shows the original design of the “Comparative Analysis of Transaction Volumes and Pricing Across Real Estate Projects”.\nAccess the original design from this link.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nresale_data &lt;- data_cleaned %&gt;%\n  filter(`Type of Sale` == \"Resale\")\n\nproject_stats &lt;- resale_data %&gt;%\n  filter(`Project Name` != \"N.A.\") %&gt;%\n  group_by(`Project Name`) %&gt;%\n  summarise(\n    Total_Units = sum(`Number of Units`, na.rm = TRUE),  # Sum up all units for each project\n    Avg_Unit_Price = mean(`Unit Price ($ PSM)`, na.rm = TRUE),  # Calculate the average price per square meter\n    .groups = \"drop\"  # Drop the grouping\n  )\n\ntop_projects &lt;- project_stats %&gt;%\n  top_n(25, Total_Units) %&gt;%\n  arrange(desc(Total_Units))\n\nproject_order &lt;- top_projects$`Project Name`\n\ntop_projects$`Project Name` &lt;- factor(top_projects$`Project Name`, levels = project_order)\nresale_data$`Project Name` &lt;- factor(resale_data$`Project Name`, levels = project_order)\n\np_units &lt;- ggplot(top_projects, aes(x = `Project Name`, y = Total_Units, fill = 'steelblue')) +\n  geom_bar(stat = \"identity\") +\n  labs(y = \"Total Number of Units\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),\n    legend.position = \"none\"\n  )\n\np_price &lt;- ggplot(resale_data, aes(x = `Project Name`, y = `Unit Price ($ PSM)`)) +\n  geom_boxplot() +\n  labs(y = \"Unit Price ($ PSM)\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),\n    legend.position = \"none\"\n  )\n\np_combined &lt;- p_units | p_price\n\np_combined"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critique-on-clarity-and-aesthetics",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critique-on-clarity-and-aesthetics",
    "title": "Take-home Exercise 2",
    "section": "Critique on Clarity and Aesthetics",
    "text": "Critique on Clarity and Aesthetics\nOverall, the original visualisation aligns with the analytical goals by allowing for a detailed examination of both sales volume and pricing across projects, offering insights that can guide strategic decisions in real estate development. Although the original visualisation managed to achieve its intended purpose, some modification would be beneficial to enhance its clarity and aesthetics.\n\nClarity\n\nLabel Overcrowding:\n\nThe project names on the x-axis are densely packed, making them hard to read. This affects the viewer’s ability to quickly identify and compare projects.\n\nScale and Balance:\n\nThe scale of the bar chart and box plot do not align well.\n\nData Visibility:\n\nIn the box plot, some boxes and whiskers are thin or compressed due to the wide range of data, which can make it difficult to discern differences between the median and quartile values across projects.\n\n\n\n\nAesthetics\n\nColor and Design:\n\nBoth plots use a simple, minimalistic color scheme which, while clean, could be enhanced to differentiate data points or groups more effectively. For example, different colors could be used to represent different quartiles in the box plot or to highlight projects with particularly high or low metrics in both plots.\n\nConsistency in Style:\n\nThere is a visual inconsistency between the bar chart and the box plot that could be distracting. The bar chart is filled with a solid color, while the box plot is more traditional with outlines. Harmonizing these styles could improve the overall cohesion of the visualization.\n\nUtilization of Space:\n\nThere’s significant empty space at the right end of both plots, especially noticeable in the box plot. This could be better utilized by compressing the x-axis or by providing additional contextual information or annotations.\n\n\n\n\nRecommendations for Improvement\n\nImproving Label Readability:\n\nRotate the position of the plot to a horizontal mode.\nReducing the number of projects with the highest ‘Total_Units’ sold from top 25 to just top 10.\nAdditional annotations could help to convey key information better for the viewer.\nBoxplot may benefit from incorporating median price directly on the plot\nUpsizing the labels on the y-axis and the x-axis\n\nAdjusting Scales and Ranges:\n\nNormalize the scales between the two charts for better comparison. This might include using logarithmic scales if the range of data is extremely wide.\nAdjust the y-axis on the box plot to focus more closely on the interquartile range, possibly using a secondary axis or break in the axis to handle outliers.\nLabels and ticks on the axes should be more readable, and using formatted numbers (like millions or rounding off) can help in understanding the scales at a glance without overwhelming with too many digits.\n\nEnhanced Color Coding and Visibility:\n\nUse color more strategically to highlight differences in data, such as coloring bars or boxes based on performance tiers (e.g., high, medium, low sales volume or prices).\nApply consistent thematic styling across both plots to enhance the visual narrative.\nThe use of a single color, while minimalist, could be expanded to differentiate data further. Using a palette to distinguish between different quartiles or highlighting specific noteworthy data points could make the visual more engaging.\nUse transparency or different shapes to denote different metrics like median, mean, or outliers in box plots.\n\n\nBy addressing these aspects, the graphs can become more intuitive, informative, and visually engaging, making them more effective as analytical tools.\n\nresale_data &lt;- data_cleaned %&gt;%\n  filter(`Type of Sale` == \"Resale\")\n\nproject_stats &lt;- resale_data %&gt;%\n  filter(`Project Name` != \"N.A.\") %&gt;%\n  group_by(`Project Name`) %&gt;%\n  summarise(\n    Total_Units = sum(`Number of Units`, na.rm = TRUE),  # Sum up all units for each project\n    Avg_Unit_Price = mean(`Unit Price ($ PSM)`, na.rm = TRUE),  # Calculate the average price per square meter\n    .groups = \"drop\"  # Drop the grouping\n  )\n\ntop_projects &lt;- project_stats %&gt;%\n  top_n(10, Total_Units) %&gt;%\n  arrange(desc(Total_Units))\n\nproject_order &lt;- top_projects$`Project Name`\n\ntop_projects$`Project Name` &lt;- factor(top_projects$`Project Name`, levels = project_order)\nresale_data$`Project Name` &lt;- factor(resale_data$`Project Name`, levels = project_order)\n\n\n\n\n\n\n\n\np_units &lt;- ggplot(top_projects, aes(x = reorder(`Project Name`, Total_Units), y = Total_Units)) +\n  geom_bar(stat = \"identity\", fill = 'steelblue') +  \n  geom_text(aes(label = paste(Total_Units, \"units sold\")), position = position_nudge(y = 8), hjust = 1.5, color = \"white\", size = 6) +  # Add annotations with \"units sold\"\n  coord_flip() +  # Flips the axes to make the bar chart horizontal\n  labs(x = \"Project Name\", y = \"Total Units Sold\") +  # Change axis labels and update names\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(angle = 0, hjust = 1, size = 20),  # Enlarge y-axis labels\n    axis.text.x = element_text(angle = 0, hjust = 1, size = 30),  # Enlarge x-axis labels\n    axis.title.x = element_text(size = 24),  # Enlarge x-axis title\n    axis.title.y = element_text(size = 24),  # Enlarge y-axis title\n    legend.position = \"none\",\n  )\n  \n\n\n\n\n\np_price &lt;- ggplot(resale_data, aes(x = `Project Name`, y = `Unit Price ($ PSM)`)) +\n  geom_boxplot() +\n  labs(y = \"Unit Price ($ PSM)\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),\n    legend.position = \"none\"\n  )\n\np_combined &lt;- p_units / p_price # Change | to / to stack plots vertically\np_combined\n\n\n\n\n\n\n\n\nMy Learning Point\nImproving these visualisations has helped me better understand the importance of clarity and precision in data presentation. Through this process, I have enhanced my ability to manipulate graphical properties in ggplot2 effectively, thereby enhancing readability and conveying information more effectively. Adjusting elements such as bar width, text annotations, and axis labels not only makes the visualisation more aesthetically pleasing but also more intuitive and informative for the audience. By customising text sizes, adjusting plot dimensions, and fine-tuning the placement of text annotations, I have observed how minor changes can significantly impact the viewer’s ability to quickly understand and interpret data. This experience has deepened my understanding of the crucial role of thoughtful visualisation design in data science, where the goal is not merely to present data but to tell a compelling story with it."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critique-on-clarity-and-aesthetics-of-the-original-visualisation",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#critique-on-clarity-and-aesthetics-of-the-original-visualisation",
    "title": "Take-home Exercise 2",
    "section": "Critique on Clarity and Aesthetics of the Original Visualisation",
    "text": "Critique on Clarity and Aesthetics of the Original Visualisation\nOverall, the original visualisation aligns with the analytical goals by allowing for a detailed examination of both sales volume and pricing across projects, offering insights that can guide strategic decisions in real estate development. With that being said, there is still room for improvements, and some modifications would be beneficial to enhance its clarity and aesthetics.\n\nClarity\n\nLabel Overcrowding:\n\nThe project names on the x-axis are densely packed, making them hard to read. This affects the viewer’s ability to quickly identify and compare projects.\n\nScale and Balance:\n\nThe scale of the bar chart and box plot do not align well.\n\nData Visibility:\n\nIn the box plot, some boxes and whiskers are thin or compressed due to the wide range of data, which can make it difficult to discern differences between the median and quartile values across projects.\n\n\n\n\nAesthetics\n\nColor and Design:\n\nBoth plots use a simple, minimalistic color scheme which, while clean, could be enhanced to differentiate data points or groups more effectively. For example, different colors could be used to represent different quartiles in the box plot or to highlight projects with particularly high or low metrics in both plots.\n\nConsistency in Style:\n\nThere is a visual inconsistency between the bar chart and the box plot that could be distracting. The bar chart is filled with a solid color, while the box plot is more traditional with outlines. Harmonizing these styles could improve the overall cohesion of the visualization.\n\nUtilization of Space:\n\nThere’s significant empty space at the right end of both plots, especially noticeable in the box plot. This could be better utilized by compressing the x-axis or by providing additional contextual information or annotations.\n\n\n\n\nRecommendations for Improvement\n\nImproving Label Readability:\n\nRotate the position of the plot to a horizontal layout.\nReducing the number of projects with the highest ‘Total_Units’ sold from top 25 to just top 10.\nAdditional annotations could help to convey key information better for the viewer.\nBoxplot may benefit from incorporating median price directly on the plot\nUpsizing the labels on the y-axis and the x-axis\nRepositioning the two plots from side-by-side to top-bottom alignment.\n\nAdjusting Scales and Ranges:\n\nAdjust the y-axis on the box plot to focus more closely on the interquartile range, possibly using a secondary axis or break in the axis to handle outliers.\nLabels and ticks on the axes should be more readable, and using formatted numbers (like millions or rounding off) can help in understanding the scales at a glance without overwhelming with too many digits.\n\nEnhanced Color Coding and Visibility:\n\nUse color more strategically to highlight differences in data, such as coloring bars or boxes based on performance tiers (e.g., high, medium, low sales volume or prices).\nApply consistent thematic styling across both plots to enhance the visual narrative.\nThe use of a single color, while minimalist, could be expanded to differentiate data further. Using a palette to distinguish between different quartiles or highlighting specific noteworthy data points could make the visual more engaging.\nUse different colours to denote different metrics like median, mean, or outliers in box plots.\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nresale_data &lt;- data_cleaned %&gt;%\n  filter(`Type of Sale` == \"Resale\")\n\nproject_stats &lt;- resale_data %&gt;%\n  filter(`Project Name` != \"N.A.\") %&gt;%\n  group_by(`Project Name`) %&gt;%\n  summarise(\n    Total_Units = sum(`Number of Units`, na.rm = TRUE),  # Sum up all units for each project\n    Avg_Unit_Price = mean(`Unit Price ($ PSM)`, na.rm = TRUE),  # Calculate the average price per square meter\n    .groups = \"drop\"  # Drop the grouping\n  )\n\ntop_projects &lt;- project_stats %&gt;%\n  top_n(10, Total_Units) %&gt;%\n  arrange(desc(Total_Units))\n\nproject_order &lt;- top_projects$`Project Name`\n\ntop_projects$`Project Name` &lt;- factor(top_projects$`Project Name`, levels = project_order)\nresale_data$`Project Name` &lt;- factor(resale_data$`Project Name`, levels = project_order)\n\n\n\np_units &lt;- ggplot(top_projects, aes(x = reorder(`Project Name`, Total_Units), y = Total_Units)) +\n  geom_bar(stat = \"identity\", fill = 'steelblue') +  \n  geom_text(aes(label = paste(Total_Units, \"units sold\")), position = position_nudge(y = 8), hjust = 1.5, color = \"white\", size = 6) +  # Add annotations with \"units sold\"\n  coord_flip() +  # Flips the axes to make the bar chart horizontal\n  labs(x = \"Project Name\", y = \"Total Units Sold\") +  # Change axis labels and update names\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(angle = 0, hjust = 1, size = 20),  # Enlarge y-axis labels\n    axis.text.x = element_text(angle = 0, hjust = 1, size = 30),  # Enlarge x-axis labels\n    axis.title.x = element_text(size = 24),  # Enlarge x-axis title\n    axis.title.y = element_text(size = 24),  # Enlarge y-axis title\n    legend.position = \"none\",\n  )\n  \n\n  \np_price &lt;- ggplot(resale_data, aes(x = `Project Name`, y = `Unit Price ($ PSM)`)) +\n  geom_boxplot() +\n  labs(y = \"Unit Price ($ PSM)\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),\n    legend.position = \"none\"\n  )\n\n\n  \n# Calculate the interquartile range to adjust y-axis limits more appropriately\niqr &lt;- IQR(resale_data$`Unit Price ($ PSM)`, na.rm = TRUE)\nq1 &lt;- quantile(resale_data$`Unit Price ($ PSM)`, 0.25, na.rm = TRUE)\nq3 &lt;- quantile(resale_data$`Unit Price ($ PSM)`, 0.75, na.rm = TRUE)\nlower_bound &lt;- max(0, q1 - 1.5 * iqr)  \nupper_bound &lt;- q3 + 1.5 * iqr\n\n# Generate the boxplot with refined axis focus and number formatting\np_price &lt;- ggplot(resale_data, aes(x = `Project Name`, y = `Unit Price ($ PSM)`)) +\n  geom_boxplot(fill = \"grey80\", colour = \"black\", outlier.colour = \"red\", outlier.shape = 16, outlier.size = 1) +\n  coord_flip() +  # Flip the axes for horizontal layout\n  scale_y_continuous(limits = c(lower_bound, upper_bound), labels = scales::comma) +  # Apply comma for thousands\n  labs(x = \"Project Name\", y = \"Unit Price ($ PSM)\") +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(angle = 0, hjust = 1, size = 20),  # Enhance readability of the x-axis labels\n    axis.text.x = element_text(angle = 0, hjust = 1, size = 30),  # Enhance readability of the y-axis labels\n    axis.title.x = element_text(size = 24),  # Enlarge x-axis title\n    axis.title.y = element_text(size = 24),  # Enlarge y-axis title\n    legend.position = \"none\",\n\n  )\n\n\n\np_combined &lt;- p_units / p_price # Change | to / to stack plots vertically\np_combined"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to visualise and analyse text data using R.\nBy the end of this hands-on exercise, you will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship.\n\n\n\n\n\n\nIn this hands-on exercise, the following R packages for handling, processing, wrangling, analysing and visualising text data will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\nThe code chunk:\n\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms,\ntidyverse, tidygraph, ggraph, igraph)\n\n\n\n\n\n\n\n\nnews20 &lt;- \"data/20news/\"\n\n\n\n\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, \n                      read_lines)) %&gt;%\n    transmute(id = basename(file), \n              text) %&gt;%\n    unnest(text)\n}\n\n\n\n\n\n\n\n\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), \n            id, text)\nwrite_rds(raw_text, \"data/rds/news20.rds\")\n\n\n\n\n\nFigure below shows the frequency of messages by newsgroup.\nThe code chunk:\n\nraw_text &lt;- read_rds(\"data/rds/news20.rds\")\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\nUsing tidy data principles in processing, analysing and visualising text data.\nMuch of the infrastructure needed for text mining with tidy data frames already exists in packages like ‘dplyr’, ‘broom’, ‘tidyr’, and ‘ggplot2’.\n\nFigure below shows the workflow using tidytext approach for processing and visualising text data.\n\n\n\nNotice that each message has some structure and extra text that we don’t want to include in our analysis. For example, every message has a header, containing field such as “from:” or “in_reply_to:” that describe the message. Some also have automated email signatures, which occur after a line like “–”.\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(\n           text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk:\n\n\n\n\ncumsum() of base R is used to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\n\n\n\n\n\n\nIn this code chunk below, regular expressions are used to remove with nested text representing quotes from other users.\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \n                     \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \n                     \"^In article &lt;\")\n  )\n\n\n\n\n\n\n\nThings to learn from the code chunk:\n\n\n\n\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions.\n\n\n\n\n\n\nIn this code chunk below, unnest_tokens() of tidytext package is used to split the dataset into tokens, while stop_words() is used to remove stop-words.\n\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nNow that we’ve removed the headers, signatures, and formatting, we can start exploring common words. For starters, we could find the most common words in the entire dataset, or within particular newsgroups.\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\n# A tibble: 5,542 × 2\n   word           n\n   &lt;chr&gt;      &lt;int&gt;\n 1 people        57\n 2 time          50\n 3 jesus         47\n 4 god           44\n 5 message       40\n 6 br            27\n 7 bible         23\n 8 drive         23\n 9 homosexual    23\n10 read          22\n# ℹ 5,532 more rows\n\n\nInstead of counting individual word, you can also count words within by newsgroup by using the code chunk below.\n\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\n\nIn this code chunk below, wordcloud() of wordcloud package is used to plot a static wordcloud.\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#learning-outcome",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to visualise and analyse text data using R.\nBy the end of this hands-on exercise, you will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getting-started",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "In this hands-on exercise, the following R packages for handling, processing, wrangling, analysing and visualising text data will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\nThe code chunk:\n\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms,\ntidyverse, tidygraph, ggraph, igraph)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "news20 &lt;- \"data/20news/\"\n\n\n\n\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, \n                      read_lines)) %&gt;%\n    transmute(id = basename(file), \n              text) %&gt;%\n    unnest(text)\n}"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-multiple-text-files-from-multiple-folders-1",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "raw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), \n            id, text)\nwrite_rds(raw_text, \"data/rds/news20.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#initial-eda",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "Figure below shows the frequency of messages by newsgroup.\nThe code chunk:\n\nraw_text &lt;- read_rds(\"data/rds/news20.rds\")\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#introducing-tidytext",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "Using tidy data principles in processing, analysing and visualising text data.\nMuch of the infrastructure needed for text mining with tidy data frames already exists in packages like ‘dplyr’, ‘broom’, ‘tidyr’, and ‘ggplot2’.\n\nFigure below shows the workflow using tidytext approach for processing and visualising text data.\n\n\n\nNotice that each message has some structure and extra text that we don’t want to include in our analysis. For example, every message has a header, containing field such as “from:” or “in_reply_to:” that describe the message. Some also have automated email signatures, which occur after a line like “–”.\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(\n           text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nThings to learn from the code chunk:\n\n\n\n\ncumsum() of base R is used to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\n\n\n\n\n\n\nIn this code chunk below, regular expressions are used to remove with nested text representing quotes from other users.\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \n                     \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \n                     \"^In article &lt;\")\n  )\n\n\n\n\n\n\n\nThings to learn from the code chunk:\n\n\n\n\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions.\n\n\n\n\n\n\nIn this code chunk below, unnest_tokens() of tidytext package is used to split the dataset into tokens, while stop_words() is used to remove stop-words.\n\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nNow that we’ve removed the headers, signatures, and formatting, we can start exploring common words. For starters, we could find the most common words in the entire dataset, or within particular newsgroups.\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\n# A tibble: 5,542 × 2\n   word           n\n   &lt;chr&gt;      &lt;int&gt;\n 1 people        57\n 2 time          50\n 3 jesus         47\n 4 god           44\n 5 message       40\n 6 br            27\n 7 bible         23\n 8 drive         23\n 9 homosexual    23\n10 read          22\n# ℹ 5,532 more rows\n\n\nInstead of counting individual word, you can also count words within by newsgroup by using the code chunk below.\n\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\n\nIn this code chunk below, wordcloud() of wordcloud package is used to plot a static wordcloud.\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05a.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05a.html#loading-r-packages",
    "title": "In-class_Ex05a",
    "section": "Loading R packages",
    "text": "Loading R packages\n\npacman::p_load(tidyverse, readtext,\n               quanteda, tidytext) \n\n\ntext_data &lt;- readtext(\"data/articles/*\")\n\n\ncorpus_text &lt;-  corpus(text_data) \nsummary(corpus_text, 5)\n\nCorpus consisting of 338 documents, showing 5 documents:\n\n                                   Text Types Tokens Sentences\n Alvarez PLC__0__0__Haacklee Herald.txt   206    433        18\n    Alvarez PLC__0__0__Lomark Daily.txt   102    170        12\n   Alvarez PLC__0__0__The News Buoy.txt    90    200         9\n Alvarez PLC__0__1__Haacklee Herald.txt    96    187         8\n    Alvarez PLC__0__1__Lomark Daily.txt   241    504        21\n\n\n\nusenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n  !word %in% stop_words$word)\n\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\nreadtext object consisting of 3260 documents and 0 docvars.\n# A data frame: 3,260 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,254 more rows\n\n\n\ntext_data_splitted &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                       delim = \"__0__\",\n                       names = c(\"X\", \"Y\"),\n                       too_few = \"align_end\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05b.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05b.html#loading-r-packages",
    "title": "In-class_Ex05b",
    "section": "Loading R packages",
    "text": "Loading R packages\n\npacman::p_load(jsonlite, tidyverse, quanteda, readtext, tidytext,\n               tidygraph, ggraph) \n\n\nmc1_data &lt;- fromJSON(\"data/mc1.json\")\n\n\nmc2_data &lt;- fromJSON(\"data/mc2.json\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "pacman::p_load(jsonlite, tidyverse, quanteda, readtext, tidytext,\n               tidygraph, ggraph) \nmc1_data &lt;- fromJSON(\"data/mc1.json\")\nmc2_data &lt;- fromJSON(\"data/mc2.json\")\n\n# Display the structure of the loaded data\nstr(mc2_data)\n\n# If mc2_data is a list, convert it to data frames\nif (is.list(mc2_data)) {\n  if (\"nodes\" %in% names(mc2_data)) {\n    nodes_df &lt;- as.data.frame(mc2_data$nodes)\n    print(\"Nodes Data Frame:\")\n    print(head(nodes_df))\n  }\n  if (\"links\" %in% names(mc2_data)) {\n    links_df &lt;- as.data.frame(mc2_data$links)\n    print(\"Links Data Frame:\")\n    print(head(links_df))\n  }\n} else {\n  # If mc2_data is directly a data frame\n  print(\"Data Frame:\")\n  print(head(mc2_data))\n}\n\n# Alternatively, you can use View() in RStudio to view the entire data frame\n# View(nodes_df)\n# View(links_df)\nView(nodes_df)\n# View(links_df)\n# View(nodes_df)\nView(links_df)\n# Read the JSON file as plain text\njson_text &lt;- readLines(\"data/mc3.json\", warn = FALSE)\n\n# Replace NaN with null\njson_text &lt;- gsub(\"NaN\", \"null\", json_text)\n\n# Write the modified JSON text back to a file (optional, for verification)\nwriteLines(json_text, \"data/mc3_fixed.json\")\n\n# Parse the modified JSON text\nmc3_data &lt;- fromJSON(json_text)\n\n# Display the structure of the loaded data\nstr(mc3_data)\n\n# If mc3_data is a list, convert it to a data frame\n# Assuming mc3_data has a structure similar to mc2_data with nodes and links\nif (is.list(mc3_data)) {\n  if (\"nodes\" %in% names(mc3_data)) {\n    nodes_df &lt;- as.data.frame(mc3_data$nodes)\n    print(\"Nodes Data Frame:\")\n    print(head(nodes_df))\n  }\n  if (\"links\" %in% names(mc3_data)) {\n    links_df &lt;- as.data.frame(mc3_data$links)\n    print(\"Links Data Frame:\")\n    print(head(links_df))\n  }\n} else {\n  # If mc3_data is directly a data frame\n  print(\"Data Frame:\")\n  print(head(mc3_data))\n}\nmc3_data &lt;- fromJSON(\"data/mc3.json\")\nstr(mc1_data)\n# View the first few rows of the nodes data frame\nhead(mc2_data$nodes)\n# Summarize the key variables in the nodes data frame\nsummary(mc2_data$nodes)\n# View the first few rows of the links data frame\nhead(mc2_data$links)\n# Summarize the key variables in the links data frame\nsummary(mc2_data$links)\n# Check for missing values in nodes and edges\nsummary(mc2_data$nodes)\nsummary(mc2_data$links)\n# Load necessary libraries\nlibrary(tidyverse)\nlibrary(tidygraph)\nlibrary(ggraph)\n\n# Check for missing values in nodes and edges\nsum(is.na(mc2_data$nodes$id))    # Check for missing node ids\nsum(is.na(mc2_data$links$source))  # Check for missing edge sources\nsum(is.na(mc2_data$links$target))  # Check for missing edge targets\n\n# Remove rows with missing id, source, or target\nmc2_data$nodes &lt;- mc2_data$nodes %&gt;% filter(!is.na(id))\nmc2_data$links &lt;- mc2_data$links %&gt;% filter(!is.na(source) & !is.na(target))\n\n# Ensure ids are unique in nodes\nmc2_data$nodes &lt;- mc2_data$nodes %&gt;% distinct(id, .keep_all = TRUE)\n\n# Convert id, source, and target to character\nmc2_data$nodes$id &lt;- as.character(mc2_data$nodes$id)\nmc2_data$links$source &lt;- as.character(mc2_data$links$source)\nmc2_data$links$target &lt;- as.character(mc2_data$links$target)\n\n# Check again if all sources and targets are in node ids\nall(mc2_data$links$source %in% mc2_data$nodes$id)\nall(mc2_data$links$target %in% mc2_data$nodes$id)\n\n# Create the tidygraph object\ngraph &lt;- tbl_graph(nodes = mc2_data$nodes, edges = mc2_data$links, directed = TRUE)\n\n# Plot the graph\nggraph(graph, layout = \"fr\") + \n  geom_edge_link(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name))) + \n  geom_node_point() + \n  geom_node_text(aes(label = name), vjust = 1, hjust = 1)\n# Check for NaN values in the dwell column\nsum(is.na(mc2_data$links$dwell))  # Count of NaN values in dwell\n\n# Optionally, replace NaN values in dwell with 0 or any appropriate value\nmc2_data$links$dwell[is.na(mc2_data$links$dwell)] &lt;- 0\n# Check for missing values in nodes and edges\nsum(is.na(mc2_data$nodes$id))    # Count of missing node ids\nsum(is.na(mc2_data$links$source))  # Count of missing edge sources\nsum(is.na(mc2_data$links$target))  # Count of missing edge targets\n\n# Check for missing values in dwell column\nsum(is.na(mc2_data$links$dwell))  # Count of missing dwell values\n# Check for NaN values in the nodes and edges data frames\nsum(is.nan(mc2_data$nodes$tonnage))\nsum(is.nan(mc2_data$nodes$length_overall))\nsum(is.nan(mc2_data$links$dwell))\n\n# Replace NaN values with appropriate defaults (e.g., 0 or another sentinel value)\nmc2_data$nodes$tonnage[is.nan(mc2_data$nodes$tonnage)] &lt;- 0\nmc2_data$nodes$length_overall[is.nan(mc2_data$nodes$length_overall)] &lt;- 0\nmc2_data$links$dwell[is.nan(mc2_data$links$dwell)] &lt;- 0\n\n# Check for infinite values and replace them\nsum(is.infinite(mc2_data$nodes$tonnage))\nsum(is.infinite(mc2_data$nodes$length_overall))\nsum(is.infinite(mc2_data$links$dwell))\n\nmc2_data$nodes$tonnage[is.infinite(mc2_data$nodes$tonnage)] &lt;- 0\nmc2_data$nodes$length_overall[is.infinite(mc2_data$nodes$length_overall)] &lt;- 0\nmc2_data$links$dwell[is.infinite(mc2_data$links$dwell)] &lt;- 0"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-task",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "pacman::p_load(jsonlite, tidyverse, quanteda, readtext, tidytext,\n               tidygraph, ggraph) \nmc1_data &lt;- fromJSON(\"data/mc1.json\")\nmc2_data &lt;- fromJSON(\"data/mc2.json\")\n\n# Display the structure of the loaded data\nstr(mc2_data)\n\n# If mc2_data is a list, convert it to data frames\nif (is.list(mc2_data)) {\n  if (\"nodes\" %in% names(mc2_data)) {\n    nodes_df &lt;- as.data.frame(mc2_data$nodes)\n    print(\"Nodes Data Frame:\")\n    print(head(nodes_df))\n  }\n  if (\"links\" %in% names(mc2_data)) {\n    links_df &lt;- as.data.frame(mc2_data$links)\n    print(\"Links Data Frame:\")\n    print(head(links_df))\n  }\n} else {\n  # If mc2_data is directly a data frame\n  print(\"Data Frame:\")\n  print(head(mc2_data))\n}\n\n# Alternatively, you can use View() in RStudio to view the entire data frame\n# View(nodes_df)\n# View(links_df)\nView(nodes_df)\n# View(links_df)\n# View(nodes_df)\nView(links_df)\n# Read the JSON file as plain text\njson_text &lt;- readLines(\"data/mc3.json\", warn = FALSE)\n\n# Replace NaN with null\njson_text &lt;- gsub(\"NaN\", \"null\", json_text)\n\n# Write the modified JSON text back to a file (optional, for verification)\nwriteLines(json_text, \"data/mc3_fixed.json\")\n\n# Parse the modified JSON text\nmc3_data &lt;- fromJSON(json_text)\n\n# Display the structure of the loaded data\nstr(mc3_data)\n\n# If mc3_data is a list, convert it to a data frame\n# Assuming mc3_data has a structure similar to mc2_data with nodes and links\nif (is.list(mc3_data)) {\n  if (\"nodes\" %in% names(mc3_data)) {\n    nodes_df &lt;- as.data.frame(mc3_data$nodes)\n    print(\"Nodes Data Frame:\")\n    print(head(nodes_df))\n  }\n  if (\"links\" %in% names(mc3_data)) {\n    links_df &lt;- as.data.frame(mc3_data$links)\n    print(\"Links Data Frame:\")\n    print(head(links_df))\n  }\n} else {\n  # If mc3_data is directly a data frame\n  print(\"Data Frame:\")\n  print(head(mc3_data))\n}\nmc3_data &lt;- fromJSON(\"data/mc3.json\")\nstr(mc1_data)\n# View the first few rows of the nodes data frame\nhead(mc2_data$nodes)\n# Summarize the key variables in the nodes data frame\nsummary(mc2_data$nodes)\n# View the first few rows of the links data frame\nhead(mc2_data$links)\n# Summarize the key variables in the links data frame\nsummary(mc2_data$links)\n# Check for missing values in nodes and edges\nsummary(mc2_data$nodes)\nsummary(mc2_data$links)\n# Load necessary libraries\nlibrary(tidyverse)\nlibrary(tidygraph)\nlibrary(ggraph)\n\n# Check for missing values in nodes and edges\nsum(is.na(mc2_data$nodes$id))    # Check for missing node ids\nsum(is.na(mc2_data$links$source))  # Check for missing edge sources\nsum(is.na(mc2_data$links$target))  # Check for missing edge targets\n\n# Remove rows with missing id, source, or target\nmc2_data$nodes &lt;- mc2_data$nodes %&gt;% filter(!is.na(id))\nmc2_data$links &lt;- mc2_data$links %&gt;% filter(!is.na(source) & !is.na(target))\n\n# Ensure ids are unique in nodes\nmc2_data$nodes &lt;- mc2_data$nodes %&gt;% distinct(id, .keep_all = TRUE)\n\n# Convert id, source, and target to character\nmc2_data$nodes$id &lt;- as.character(mc2_data$nodes$id)\nmc2_data$links$source &lt;- as.character(mc2_data$links$source)\nmc2_data$links$target &lt;- as.character(mc2_data$links$target)\n\n# Check again if all sources and targets are in node ids\nall(mc2_data$links$source %in% mc2_data$nodes$id)\nall(mc2_data$links$target %in% mc2_data$nodes$id)\n\n# Create the tidygraph object\ngraph &lt;- tbl_graph(nodes = mc2_data$nodes, edges = mc2_data$links, directed = TRUE)\n\n# Plot the graph\nggraph(graph, layout = \"fr\") + \n  geom_edge_link(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name))) + \n  geom_node_point() + \n  geom_node_text(aes(label = name), vjust = 1, hjust = 1)\n# Check for NaN values in the dwell column\nsum(is.na(mc2_data$links$dwell))  # Count of NaN values in dwell\n\n# Optionally, replace NaN values in dwell with 0 or any appropriate value\nmc2_data$links$dwell[is.na(mc2_data$links$dwell)] &lt;- 0\n# Check for missing values in nodes and edges\nsum(is.na(mc2_data$nodes$id))    # Count of missing node ids\nsum(is.na(mc2_data$links$source))  # Count of missing edge sources\nsum(is.na(mc2_data$links$target))  # Count of missing edge targets\n\n# Check for missing values in dwell column\nsum(is.na(mc2_data$links$dwell))  # Count of missing dwell values\n# Check for NaN values in the nodes and edges data frames\nsum(is.nan(mc2_data$nodes$tonnage))\nsum(is.nan(mc2_data$nodes$length_overall))\nsum(is.nan(mc2_data$links$dwell))\n\n# Replace NaN values with appropriate defaults (e.g., 0 or another sentinel value)\nmc2_data$nodes$tonnage[is.nan(mc2_data$nodes$tonnage)] &lt;- 0\nmc2_data$nodes$length_overall[is.nan(mc2_data$nodes$length_overall)] &lt;- 0\nmc2_data$links$dwell[is.nan(mc2_data$links$dwell)] &lt;- 0\n\n# Check for infinite values and replace them\nsum(is.infinite(mc2_data$nodes$tonnage))\nsum(is.infinite(mc2_data$nodes$length_overall))\nsum(is.infinite(mc2_data$links$dwell))\n\nmc2_data$nodes$tonnage[is.infinite(mc2_data$nodes$tonnage)] &lt;- 0\nmc2_data$nodes$length_overall[is.infinite(mc2_data$nodes$length_overall)] &lt;- 0\nmc2_data$links$dwell[is.infinite(mc2_data$links$dwell)] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package.\n\n\n\n\n\n\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\n\nCode\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\n\n\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#overview",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\n\nCode\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#the-data",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "The data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#loading-r-packages",
    "title": "In-class_Ex06",
    "section": "Loading R packages",
    "text": "Loading R packages\n\npacman::p_load(tidyverse, corporaexplorer, quanteda, stringi, rvest) \n\n\nbible &lt;- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")\n\n\n#collapsing into one string\nbible &lt;- paste(bible, collapse = \"\\n\")\n\n\n# Identifying the beginning and end of the Bible / stripping PJ metadata\n # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\n\n# In the file, every book in the bible is preceded by five newlines,\n  # which we use to split our string into a vector where each element is a book.\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  # Removing the heading \"The New Testament of the King James Bible\",\n              # which also was preceded by five newlines.\n\n\n# Because of the structure of the text in the file:\n  # Replacing double or more newlines with two newlines, and a single newline with space.\nbooks &lt;- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %&gt;%\n    str_replace_all(\"\\n\", \" \") %&gt;%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]  # The two first elements are not books\n\n\n# Identifying new chapters within each book and split the text into chapters.\n# (The first characters in chapter 2 will e.g. be 2:1)\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %&gt;%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n\n# Removing the chapter headings from the text (we want them as metadata).\nchapters &lt;- lapply(chapters, function(x) x[-1])\n\n\n# We are not quite happy with the long book titles in the King James Bible,\n  # so we retrieve shorter versions from esv.org which will take up less\n  # space in the corpus map plot.\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))\n\n\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\nbible_df &lt;- tidyr::unnest(bible_df, Text)\n\n\n# As this is a corpus which is not organised by date,\n  # we set `date_based_corpus` to `FALSE`.\n# Because we want to organise our exploration around the books in the Bible,\n  # we pass `\"Book\"` to the `grouping_variable` argument.\n# We specify which metadata columns we want to be displayed in the\n  # \"Document information\" tab, using the `columns_doc_info` argument.\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n\n\nclass(KJB)\n\n[1] \"corporaexplorerobject\"\n\n\n\nexplore(KJB)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06a.html#loading-r-packages",
    "title": "In-class_Ex06a",
    "section": "Loading R packages",
    "text": "Loading R packages\n\npacman::p_load(tidyverse, corporaexplorer, quanteda, stringi, rvest) \n\n\nbible &lt;- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")\n\n\n#collapsing into one string\nbible &lt;- paste(bible, collapse = \"\\n\")\n\n\n# Identifying the beginning and end of the Bible / stripping PJ metadata\n # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\n\n# In the file, every book in the bible is preceded by five newlines,\n  # which we use to split our string into a vector where each element is a book.\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  # Removing the heading \"The New Testament of the King James Bible\",\n              # which also was preceded by five newlines.\n\n\n# Because of the structure of the text in the file:\n  # Replacing double or more newlines with two newlines, and a single newline with space.\nbooks &lt;- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %&gt;%\n    str_replace_all(\"\\n\", \" \") %&gt;%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]  # The two first elements are not books\n\n\n# Identifying new chapters within each book and split the text into chapters.\n# (The first characters in chapter 2 will e.g. be 2:1)\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %&gt;%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n\n# Removing the chapter headings from the text (we want them as metadata).\nchapters &lt;- lapply(chapters, function(x) x[-1])\n\n\n# We are not quite happy with the long book titles in the King James Bible,\n  # so we retrieve shorter versions from esv.org which will take up less\n  # space in the corpus map plot.\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))\n\n\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\nbible_df &lt;- tidyr::unnest(bible_df, Text)\n\n\n# As this is a corpus which is not organised by date,\n  # we set `date_based_corpus` to `FALSE`.\n# Because we want to organise our exploration around the books in the Bible,\n  # we pass `\"Book\"` to the `grouping_variable` argument.\n# We specify which metadata columns we want to be displayed in the\n  # \"Document information\" tab, using the `columns_doc_info` argument.\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n\n\nclass(KJB)\n\n[1] \"corporaexplorerobject\"\n\n\n\nexplore(KJB)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06b.html#loading-r-packages",
    "title": "In-class_Ex06b",
    "section": "Loading R packages",
    "text": "Loading R packages\n\npacman::p_load(jsonlite, tidygraph, ggraph,\n               visNetwork, graphlayouts, tidyverse) \n\n\nmc3_data &lt;- fromJSON(\"data/MC3_2023.json\")\n\n\nclass(mc3_data)\n\n[1] \"list\"\n\n\n\nmc3_edges &lt;- as_tibble(mc3_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source = as.character(source),\n          target = as.character(target),\n          type = as.character(type)) %&gt;%\n  group_by(source, target, type) %&gt;%\n    summarise(weights = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  ungroup()\n\n\nmc3_nodes &lt;- as_tibble(mc3_data$nodes) %&gt;%\n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %&gt;%\n  select(id, country, type, revenue_omu, product_services)\n\n\nid1 &lt;-mc3_edges %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\nid2 &lt;- mc3_edges %&gt;%\n  select(target) %&gt;%\n  rename(id = target)\nmc3_nodes1 &lt;- rbind(id1, id2) %&gt;%\n  distinct() %&gt;%\n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n\n\nmc3_graph &lt;- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness(),\n         closeness_centralilty = centrality_closeness())\n\n\nmc3_graph %&gt;%\n  filter(betweenness_centrality &gt;= 300000) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(size = betweenness_centrality,\n                      colors = \"lightblue\",\n                      alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10))+\n  theme_graph()"
  }
]